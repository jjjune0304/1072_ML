{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy, time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init\n",
    "import torch.functional as F\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "### cuda gpu ###\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WMAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WMAE, self).__init__()\n",
    "\n",
    "    def forward(self, weight, imput, target):\n",
    "        out = torch.abs(imput - target)\n",
    "        out = out.mm(weight.t())\n",
    "        loss = out.mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NAE, self).__init__()\n",
    "\n",
    "    def forward(self, weight, imput, target):\n",
    "        out = torch.abs(imput - target)\n",
    "        t = 1 / target\n",
    "        out = out * t\n",
    "        loss = out.sum(dim=1,keepdim=False).mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class feature(Dataset):\n",
    "    def __init__(self, X, Y, TX, TY, train=True):\n",
    "        self.train = train        \n",
    "        self.x = X\n",
    "        self.y = Y\n",
    "        self.tx = TX\n",
    "        self.ty = TY\n",
    "    def __len__(self):\n",
    "        return(len(self.x) if self.train else len(self.tx))\n",
    "    def __getitem__(self,idx):\n",
    "        tmp_y = self.y[idx] if self.train else ty[idx]\n",
    "        return(self.x[idx] if self.train else self.tx[idx], tmp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load('X_train.npz') as data:\n",
    "    X_tr = data['arr_0']\n",
    "    \n",
    "with np.load('Y_train.npz') as data:\n",
    "    Y_tr = data['arr_0']\n",
    "\n",
    "with np.load('X_test.npz') as data:\n",
    "    X_test = data['arr_0']\n",
    "\n",
    "X, VX , Y, VY = train_test_split(X_tr, Y_tr, test_size=0.1,random_state=11)\n",
    "X = torch.from_numpy(X).float()\n",
    "VX = torch.from_numpy(VX).float()\n",
    "Y = torch.from_numpy(Y).float()\n",
    "VY = torch.from_numpy(VY).float()\n",
    "TX = torch.from_numpy(X_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10000]) torch.Size([1, 10000])\n"
     ]
    }
   ],
   "source": [
    "means = X.mean(dim=0, keepdim=True)\n",
    "stds = X.std(dim=0, keepdim=True)\n",
    "print(means.shape,stds.shape)\n",
    "normalized_X = (X - means) / stds\n",
    "normalized_VX = (VX - means) / stds\n",
    "normalized_TX = (TX - means) / stds\n",
    "\n",
    "tr_set = feature(normalized_X,Y,normalized_VX,VY,train=True)\n",
    "\n",
    "tr = DataLoader(tr_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def err(predict,Y):\n",
    "    w = torch.as_tensor([300, 1, 200],dtype=torch.float).unsqueeze(0)\n",
    "    out = torch.abs(predict - Y)\n",
    "    wmae = out * w\n",
    "    loss = wmae.mean(dim=0,keepdim=False)  \n",
    "    rate_err, mesh_err, alpha_err = loss[0],loss[1],0\n",
    "    print('WMAE: alpha err = {0}, mesh_size err = {1}, penetration rate err = {2}'.format(alpha_err,mesh_err,rate_err))\n",
    "    WMAE = alpha_err + mesh_err + rate_err\n",
    "    print('WMAE = {0}'.format(WMAE))\n",
    "    '''\n",
    "    diff = np.divide(diff,Y)\n",
    "    rate_err, mesh_err, alpha_err = np.sum(diff[:,0]) / N, np.sum(diff[:,1]) / N, np.sum(diff[:,2]) / N\n",
    "    print('NAE: alpha err = {0}, mesh_size err = {1}, penetration rate err = {2}'.format(alpha_err,mesh_err,rate_err))\n",
    "    NAE = alpha_err + mesh_err + rate_err\n",
    "    print('NAE = {0}'.format(NAE))\n",
    "    '''\n",
    "\n",
    "def WERR(w,predict,Y):\n",
    "    out = torch.abs(predict - Y)\n",
    "    loss = out.mean(dim=0,keepdim=False,dtype=torch.float) * w \n",
    "    print('weight = {0}, err = {1}'.format(w,loss))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(linear_model, self).__init__()\n",
    "        self.linear1 = nn.Linear(10000, 30)\n",
    "        self.linear2 = nn.Linear(30, 30)\n",
    "        self.linear3 = nn.Linear(30, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_modelv2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(linear_modelv2, self).__init__()\n",
    "        self.linear1 = nn.Linear(5000, 20)\n",
    "        self.linear2 = nn.Linear(5000, 20)\n",
    "        self.linear3 = nn.Linear(40, 40)\n",
    "        self.linear4 = nn.Linear(40, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.linear1(x[:,0:5000])\n",
    "        x1 = F.relu(x1)\n",
    "        x2 = self.linear2(x[:,5000:])\n",
    "        x2 = F.relu(x2)\n",
    "        x = torch.cat((x1,x2),-1)\n",
    "        x = self.linear3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is epoch    0\n",
      "Batch:  668/ 668 loss: 10526.1479 total time:  2.98s\n",
      "Training set\n",
      "weight = 1, err = 61.469970703125\n",
      "Testing set\n",
      "weight = 1, err = 60.22227096557617\n",
      "This is epoch    1\n",
      "Batch:  668/ 668 loss: 4740.5920 total time:  2.26s\n",
      "Training set\n",
      "weight = 1, err = 48.04555892944336\n",
      "Testing set\n",
      "weight = 1, err = 47.509639739990234\n",
      "This is epoch    2\n",
      "Batch:  668/ 668 loss: 3341.8614 total time:  2.41s\n",
      "Training set\n",
      "weight = 1, err = 43.87220001220703\n",
      "Testing set\n",
      "weight = 1, err = 43.90939712524414\n",
      "This is epoch    3\n",
      "Batch:  668/ 668 loss: 2987.6335 total time:  2.32s\n",
      "Training set\n",
      "weight = 1, err = 42.25236129760742\n",
      "Testing set\n",
      "weight = 1, err = 42.45458221435547\n",
      "This is epoch    4\n",
      "Batch:  668/ 668 loss: 2805.8457 total time:  2.30s\n",
      "Training set\n",
      "weight = 1, err = 40.635738372802734\n",
      "Testing set\n",
      "weight = 1, err = 40.861515045166016\n",
      "This is epoch    5\n",
      "Batch:  668/ 668 loss: 2618.0720 total time:  2.31s\n",
      "Training set\n",
      "weight = 1, err = 39.369136810302734\n",
      "Testing set\n",
      "weight = 1, err = 39.52349853515625\n",
      "This is epoch    6\n",
      "Batch:  668/ 668 loss: 2444.2035 total time:  2.39s\n",
      "Training set\n",
      "weight = 1, err = 38.66145706176758\n",
      "Testing set\n",
      "weight = 1, err = 38.85953903198242\n",
      "This is epoch    7\n",
      "Batch:  668/ 668 loss: 2313.7115 total time:  2.37s\n",
      "Training set\n",
      "weight = 1, err = 37.17666244506836\n",
      "Testing set\n",
      "weight = 1, err = 37.3971061706543\n",
      "This is epoch    8\n",
      "Batch:  668/ 668 loss: 2202.6134 total time:  2.06s\n",
      "Training set\n",
      "weight = 1, err = 36.44759750366211\n",
      "Testing set\n",
      "weight = 1, err = 36.64479446411133\n",
      "This is epoch    9\n",
      "Batch:  668/ 668 loss: 2123.3573 total time:  2.28s\n",
      "Training set\n",
      "weight = 1, err = 35.26094055175781\n",
      "Testing set\n",
      "weight = 1, err = 35.565860748291016\n",
      "This is epoch   10\n",
      "Batch:  668/ 668 loss: 2051.0620 total time:  2.06s\n",
      "Training set\n",
      "weight = 1, err = 34.814674377441406\n",
      "Testing set\n",
      "weight = 1, err = 34.99138641357422\n",
      "This is epoch   11\n",
      "Batch:  668/ 668 loss: 1992.6062 total time:  2.36s\n",
      "Training set\n",
      "weight = 1, err = 33.92534637451172\n",
      "Testing set\n",
      "weight = 1, err = 34.31365966796875\n",
      "This is epoch   12\n",
      "Batch:  668/ 668 loss: 1938.7388 total time:  2.22s\n",
      "Training set\n",
      "weight = 1, err = 34.34744644165039\n",
      "Testing set\n",
      "weight = 1, err = 34.77925491333008\n",
      "This is epoch   13\n",
      "Batch:  668/ 668 loss: 1885.6522 total time:  2.23s\n",
      "Training set\n",
      "weight = 1, err = 32.98341369628906\n",
      "Testing set\n",
      "weight = 1, err = 33.38267517089844\n",
      "This is epoch   14\n",
      "Batch:  668/ 668 loss: 1840.7806 total time:  2.16s\n",
      "Training set\n",
      "weight = 1, err = 32.97616195678711\n",
      "Testing set\n",
      "weight = 1, err = 33.48092269897461\n",
      "This is epoch   15\n",
      "Batch:  668/ 668 loss: 1797.8105 total time:  2.16s\n",
      "Training set\n",
      "weight = 1, err = 32.32454299926758\n",
      "Testing set\n",
      "weight = 1, err = 32.87508773803711\n",
      "This is epoch   16\n",
      "Batch:  668/ 668 loss: 1763.7545 total time:  2.17s\n",
      "Training set\n",
      "weight = 1, err = 31.757102966308594\n",
      "Testing set\n",
      "weight = 1, err = 32.213314056396484\n",
      "This is epoch   17\n",
      "Batch:  668/ 668 loss: 1725.3348 total time:  2.21s\n",
      "Training set\n",
      "weight = 1, err = 31.641704559326172\n",
      "Testing set\n",
      "weight = 1, err = 32.00151062011719\n",
      "This is epoch   18\n",
      "Batch:  668/ 668 loss: 1690.7899 total time:  2.12s\n",
      "Training set\n",
      "weight = 1, err = 31.038923263549805\n",
      "Testing set\n",
      "weight = 1, err = 31.423099517822266\n",
      "This is epoch   19\n",
      "Batch:  668/ 668 loss: 1658.8656 total time:  2.13s\n",
      "Training set\n",
      "weight = 1, err = 30.906747817993164\n",
      "Testing set\n",
      "weight = 1, err = 31.26804542541504\n",
      "This is epoch   20\n",
      "Batch:  668/ 668 loss: 1626.0243 total time:  2.32s\n",
      "Training set\n",
      "weight = 1, err = 30.636756896972656\n",
      "Testing set\n",
      "weight = 1, err = 31.133766174316406\n",
      "This is epoch   21\n",
      "Batch:  668/ 668 loss: 1596.3840 total time:  2.15s\n",
      "Training set\n",
      "weight = 1, err = 30.3937931060791\n",
      "Testing set\n",
      "weight = 1, err = 30.82614517211914\n",
      "This is epoch   22\n",
      "Batch:  668/ 668 loss: 1568.2641 total time:  2.36s\n",
      "Training set\n",
      "weight = 1, err = 29.874332427978516\n",
      "Testing set\n",
      "weight = 1, err = 30.39444351196289\n",
      "This is epoch   23\n",
      "Batch:  668/ 668 loss: 1536.4429 total time:  2.11s\n",
      "Training set\n",
      "weight = 1, err = 29.52433967590332\n",
      "Testing set\n",
      "weight = 1, err = 29.974130630493164\n",
      "This is epoch   24\n",
      "Batch:  668/ 668 loss: 1513.9348 total time:  2.12s\n",
      "Training set\n",
      "weight = 1, err = 29.27476692199707\n",
      "Testing set\n",
      "weight = 1, err = 29.750638961791992\n",
      "This is epoch   25\n",
      "Batch:  668/ 668 loss: 1485.8135 total time:  2.28s\n",
      "Training set\n",
      "weight = 1, err = 29.154447555541992\n",
      "Testing set\n",
      "weight = 1, err = 29.669700622558594\n",
      "This is epoch   26\n",
      "Batch:  668/ 668 loss: 1460.9446 total time:  2.28s\n",
      "Training set\n",
      "weight = 1, err = 28.698482513427734\n",
      "Testing set\n",
      "weight = 1, err = 29.23356819152832\n",
      "This is epoch   27\n",
      "Batch:  668/ 668 loss: 1433.0401 total time:  2.18s\n",
      "Training set\n",
      "weight = 1, err = 28.432552337646484\n",
      "Testing set\n",
      "weight = 1, err = 28.865171432495117\n",
      "This is epoch   28\n",
      "Batch:  668/ 668 loss: 1409.5689 total time:  2.17s\n",
      "Training set\n",
      "weight = 1, err = 28.257190704345703\n",
      "Testing set\n",
      "weight = 1, err = 28.748138427734375\n",
      "This is epoch   29\n",
      "Batch:  668/ 668 loss: 1380.1508 total time:  2.12s\n",
      "Training set\n",
      "weight = 1, err = 28.603771209716797\n",
      "Testing set\n",
      "weight = 1, err = 29.097780227661133\n",
      "This is epoch   30\n",
      "Batch:  668/ 668 loss: 1369.5449 total time:  2.02s\n",
      "Training set\n",
      "weight = 1, err = 27.933977127075195\n",
      "Testing set\n",
      "weight = 1, err = 28.39181900024414\n",
      "This is epoch   31\n",
      "Batch:  668/ 668 loss: 1343.4866 total time:  2.11s\n",
      "Training set\n",
      "weight = 1, err = 28.067211151123047\n",
      "Testing set\n",
      "weight = 1, err = 28.454431533813477\n",
      "This is epoch   32\n",
      "Batch:  668/ 668 loss: 1323.2755 total time:  2.14s\n",
      "Training set\n",
      "weight = 1, err = 27.39649200439453\n",
      "Testing set\n",
      "weight = 1, err = 27.801387786865234\n",
      "This is epoch   33\n",
      "Batch:  668/ 668 loss: 1305.1618 total time:  2.19s\n",
      "Training set\n",
      "weight = 1, err = 27.623144149780273\n",
      "Testing set\n",
      "weight = 1, err = 28.12068748474121\n",
      "This is epoch   34\n",
      "Batch:  668/ 668 loss: 1293.6977 total time:  2.20s\n",
      "Training set\n",
      "weight = 1, err = 27.007434844970703\n",
      "Testing set\n",
      "weight = 1, err = 27.450292587280273\n",
      "This is epoch   35\n",
      "Batch:  668/ 668 loss: 1277.8461 total time:  2.23s\n",
      "Training set\n",
      "weight = 1, err = 26.919857025146484\n",
      "Testing set\n",
      "weight = 1, err = 27.40452766418457\n",
      "This is epoch   36\n",
      "Batch:  668/ 668 loss: 1255.9978 total time:  2.23s\n",
      "Training set\n",
      "weight = 1, err = 27.18229866027832\n",
      "Testing set\n",
      "weight = 1, err = 27.583948135375977\n",
      "This is epoch   37\n",
      "Batch:  668/ 668 loss: 1241.3356 total time:  2.10s\n",
      "Training set\n",
      "weight = 1, err = 26.453283309936523\n",
      "Testing set\n",
      "weight = 1, err = 26.86445426940918\n",
      "This is epoch   38\n",
      "Batch:  668/ 668 loss: 1231.2817 total time:  2.26s\n",
      "Training set\n",
      "weight = 1, err = 26.539793014526367\n",
      "Testing set\n",
      "weight = 1, err = 27.02196502685547\n",
      "This is epoch   39\n",
      "Batch:  668/ 668 loss: 1222.7746 total time:  2.23s\n",
      "Training set\n",
      "weight = 1, err = 26.264169692993164\n",
      "Testing set\n",
      "weight = 1, err = 26.692148208618164\n",
      "This is epoch   40\n",
      "Batch:  668/ 668 loss: 1206.6291 total time:  2.07s\n",
      "Training set\n",
      "weight = 1, err = 26.44325065612793\n",
      "Testing set\n",
      "weight = 1, err = 26.82024574279785\n",
      "This is epoch   41\n",
      "Batch:  668/ 668 loss: 1193.3285 total time:  2.28s\n",
      "Training set\n",
      "weight = 1, err = 25.910686492919922\n",
      "Testing set\n",
      "weight = 1, err = 26.344589233398438\n",
      "This is epoch   42\n",
      "Batch:  668/ 668 loss: 1186.4028 total time:  2.35s\n",
      "Training set\n",
      "weight = 1, err = 25.984216690063477\n",
      "Testing set\n",
      "weight = 1, err = 26.49679946899414\n",
      "This is epoch   43\n",
      "Batch:  668/ 668 loss: 1176.8263 total time:  2.17s\n",
      "Training set\n",
      "weight = 1, err = 25.795379638671875\n",
      "Testing set\n",
      "weight = 1, err = 26.296499252319336\n",
      "This is epoch   44\n",
      "Batch:  668/ 668 loss: 1171.0724 total time:  2.15s\n",
      "Training set\n",
      "weight = 1, err = 25.712329864501953\n",
      "Testing set\n",
      "weight = 1, err = 26.16090965270996\n",
      "This is epoch   45\n",
      "Batch:  668/ 668 loss: 1161.5944 total time:  2.21s\n",
      "Training set\n",
      "weight = 1, err = 25.591693878173828\n",
      "Testing set\n",
      "weight = 1, err = 26.062763214111328\n",
      "This is epoch   46\n",
      "Batch:  668/ 668 loss: 1152.4921 total time:  2.11s\n",
      "Training set\n",
      "weight = 1, err = 26.01690673828125\n",
      "Testing set\n",
      "weight = 1, err = 26.520183563232422\n",
      "This is epoch   47\n",
      "Batch:  668/ 668 loss: 1143.4525 total time:  2.24s\n",
      "Training set\n",
      "weight = 1, err = 25.55423355102539\n",
      "Testing set\n",
      "weight = 1, err = 26.029611587524414\n",
      "This is epoch   48\n",
      "Batch:  668/ 668 loss: 1146.6204 total time:  2.26s\n",
      "Training set\n",
      "weight = 1, err = 25.45128631591797\n",
      "Testing set\n",
      "weight = 1, err = 25.904855728149414\n",
      "This is epoch   49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  668/ 668 loss: 1130.1094 total time:  2.10s\n",
      "Training set\n",
      "weight = 1, err = 25.253435134887695\n",
      "Testing set\n",
      "weight = 1, err = 25.803768157958984\n",
      "This is epoch   50\n",
      "Batch:  668/ 668 loss: 1125.6872 total time:  2.09s\n",
      "Training set\n",
      "weight = 1, err = 25.26895523071289\n",
      "Testing set\n",
      "weight = 1, err = 25.811674118041992\n",
      "This is epoch   51\n",
      "Batch:  668/ 668 loss: 1124.3472 total time:  2.16s\n",
      "Training set\n",
      "weight = 1, err = 25.26375389099121\n",
      "Testing set\n",
      "weight = 1, err = 25.825098037719727\n",
      "This is epoch   52\n",
      "Batch:  668/ 668 loss: 1121.6965 total time:  2.07s\n",
      "Training set\n",
      "weight = 1, err = 25.069416046142578\n",
      "Testing set\n",
      "weight = 1, err = 25.57004165649414\n",
      "This is epoch   53\n",
      "Batch:  668/ 668 loss: 1111.6279 total time:  1.91s\n",
      "Training set\n",
      "weight = 1, err = 25.277122497558594\n",
      "Testing set\n",
      "weight = 1, err = 25.839698791503906\n",
      "This is epoch   54\n",
      "Batch:  668/ 668 loss: 1107.5170 total time:  2.06s\n",
      "Training set\n",
      "weight = 1, err = 25.191280364990234\n",
      "Testing set\n",
      "weight = 1, err = 25.717140197753906\n",
      "This is epoch   55\n",
      "Batch:  668/ 668 loss: 1109.7963 total time:  2.12s\n",
      "Training set\n",
      "weight = 1, err = 25.338092803955078\n",
      "Testing set\n",
      "weight = 1, err = 25.799419403076172\n",
      "This is epoch   56\n",
      "Batch:  668/ 668 loss: 1103.9160 total time:  2.28s\n",
      "Training set\n",
      "weight = 1, err = 25.05657386779785\n",
      "Testing set\n",
      "weight = 1, err = 25.555532455444336\n",
      "This is epoch   57\n",
      "Batch:  668/ 668 loss: 1100.9132 total time:  2.25s\n",
      "Training set\n",
      "weight = 1, err = 24.986522674560547\n",
      "Testing set\n",
      "weight = 1, err = 25.53724479675293\n",
      "This is epoch   58\n",
      "Batch:  668/ 668 loss: 1093.9858 total time:  2.28s\n",
      "Training set\n",
      "weight = 1, err = 24.847929000854492\n",
      "Testing set\n",
      "weight = 1, err = 25.41219711303711\n",
      "This is epoch   59\n",
      "Batch:  668/ 668 loss: 1089.7426 total time:  2.23s\n",
      "Training set\n",
      "weight = 1, err = 24.777584075927734\n",
      "Testing set\n",
      "weight = 1, err = 25.34126091003418\n",
      "This is epoch   60\n",
      "Batch:  668/ 668 loss: 1093.1855 total time:  2.21s\n",
      "Training set\n",
      "weight = 1, err = 24.831432342529297\n",
      "Testing set\n",
      "weight = 1, err = 25.504127502441406\n",
      "This is epoch   61\n",
      "Batch:  668/ 668 loss: 1086.3295 total time:  2.27s\n",
      "Training set\n",
      "weight = 1, err = 24.756221771240234\n",
      "Testing set\n",
      "weight = 1, err = 25.364173889160156\n",
      "This is epoch   62\n",
      "Batch:  668/ 668 loss: 1082.5486 total time:  2.21s\n",
      "Training set\n",
      "weight = 1, err = 24.558269500732422\n",
      "Testing set\n",
      "weight = 1, err = 25.173171997070312\n",
      "This is epoch   63\n",
      "Batch:  668/ 668 loss: 1079.9064 total time:  2.13s\n",
      "Training set\n",
      "weight = 1, err = 24.74783706665039\n",
      "Testing set\n",
      "weight = 1, err = 25.360563278198242\n",
      "This is epoch   64\n",
      "Batch:  668/ 668 loss: 1074.7177 total time:  2.08s\n",
      "Training set\n",
      "weight = 1, err = 24.526813507080078\n",
      "Testing set\n",
      "weight = 1, err = 25.11113929748535\n",
      "This is epoch   65\n",
      "Batch:  668/ 668 loss: 1082.6464 total time:  2.16s\n",
      "Training set\n",
      "weight = 1, err = 24.409677505493164\n",
      "Testing set\n",
      "weight = 1, err = 25.03284454345703\n",
      "This is epoch   66\n",
      "Batch:  668/ 668 loss: 1067.6956 total time:  2.16s\n",
      "Training set\n",
      "weight = 1, err = 24.840972900390625\n",
      "Testing set\n",
      "weight = 1, err = 25.405441284179688\n",
      "This is epoch   67\n",
      "Batch:  668/ 668 loss: 1065.0399 total time:  2.37s\n",
      "Training set\n",
      "weight = 1, err = 24.564376831054688\n",
      "Testing set\n",
      "weight = 1, err = 25.186992645263672\n",
      "This is epoch   68\n",
      "Batch:  668/ 668 loss: 1066.2764 total time:  2.41s\n",
      "Training set\n",
      "weight = 1, err = 24.85639762878418\n",
      "Testing set\n",
      "weight = 1, err = 25.433513641357422\n",
      "This is epoch   69\n",
      "Batch:  668/ 668 loss: 1063.7921 total time:  2.20s\n",
      "Training set\n",
      "weight = 1, err = 24.354949951171875\n",
      "Testing set\n",
      "weight = 1, err = 24.998104095458984\n",
      "This is epoch   70\n",
      "Batch:  668/ 668 loss: 1060.5741 total time:  1.94s\n",
      "Training set\n",
      "weight = 1, err = 24.296525955200195\n",
      "Testing set\n",
      "weight = 1, err = 24.91570472717285\n",
      "This is epoch   71\n",
      "Batch:  668/ 668 loss: 1058.2598 total time:  2.06s\n",
      "Training set\n",
      "weight = 1, err = 24.33828353881836\n",
      "Testing set\n",
      "weight = 1, err = 25.0202579498291\n",
      "This is epoch   72\n",
      "Batch:  668/ 668 loss: 1060.1287 total time:  2.20s\n",
      "Training set\n",
      "weight = 1, err = 24.308021545410156\n",
      "Testing set\n",
      "weight = 1, err = 24.931194305419922\n",
      "This is epoch   73\n",
      "Batch:  668/ 668 loss: 1055.4248 total time:  2.10s\n",
      "Training set\n",
      "weight = 1, err = 24.14915657043457\n",
      "Testing set\n",
      "weight = 1, err = 24.764253616333008\n",
      "This is epoch   74\n",
      "Batch:  668/ 668 loss: 1054.3197 total time:  2.12s\n",
      "Training set\n",
      "weight = 1, err = 24.157846450805664\n",
      "Testing set\n",
      "weight = 1, err = 24.814565658569336\n",
      "This is epoch   75\n",
      "Batch:  668/ 668 loss: 1049.4990 total time:  2.14s\n",
      "Training set\n",
      "weight = 1, err = 24.318689346313477\n",
      "Testing set\n",
      "weight = 1, err = 24.960464477539062\n",
      "This is epoch   76\n",
      "Batch:  668/ 668 loss: 1041.9005 total time:  2.11s\n",
      "Training set\n",
      "weight = 1, err = 24.273054122924805\n",
      "Testing set\n",
      "weight = 1, err = 24.96344566345215\n",
      "This is epoch   77\n",
      "Batch:  668/ 668 loss: 1051.0349 total time:  2.10s\n",
      "Training set\n",
      "weight = 1, err = 24.433252334594727\n",
      "Testing set\n",
      "weight = 1, err = 25.056848526000977\n",
      "This is epoch   78\n",
      "Batch:  668/ 668 loss: 1043.6127 total time:  1.88s\n",
      "Training set\n",
      "weight = 1, err = 24.19042205810547\n",
      "Testing set\n",
      "weight = 1, err = 24.929887771606445\n",
      "This is epoch   79\n",
      "Batch:  668/ 668 loss: 1039.4330 total time:  2.08s\n",
      "Training set\n",
      "weight = 1, err = 24.634424209594727\n",
      "Testing set\n",
      "weight = 1, err = 25.254539489746094\n",
      "This is epoch   80\n",
      "Batch:  668/ 668 loss: 1042.5871 total time:  2.22s\n",
      "Training set\n",
      "weight = 1, err = 24.105926513671875\n",
      "Testing set\n",
      "weight = 1, err = 24.830543518066406\n",
      "This is epoch   81\n",
      "Batch:  668/ 668 loss: 1032.6883 total time:  2.23s\n",
      "Training set\n",
      "weight = 1, err = 23.997997283935547\n",
      "Testing set\n",
      "weight = 1, err = 24.665000915527344\n",
      "This is epoch   82\n",
      "Batch:  668/ 668 loss: 1037.0450 total time:  2.15s\n",
      "Training set\n",
      "weight = 1, err = 23.914230346679688\n",
      "Testing set\n",
      "weight = 1, err = 24.609027862548828\n",
      "This is epoch   83\n",
      "Batch:  668/ 668 loss: 1029.4718 total time:  2.18s\n",
      "Training set\n",
      "weight = 1, err = 24.015371322631836\n",
      "Testing set\n",
      "weight = 1, err = 24.753929138183594\n",
      "This is epoch   84\n",
      "Batch:  668/ 668 loss: 1022.8208 total time:  2.21s\n",
      "Training set\n",
      "weight = 1, err = 24.156126022338867\n",
      "Testing set\n",
      "weight = 1, err = 24.837902069091797\n",
      "This is epoch   85\n",
      "Batch:  668/ 668 loss: 1029.2619 total time:  2.17s\n",
      "Training set\n",
      "weight = 1, err = 23.8680362701416\n",
      "Testing set\n",
      "weight = 1, err = 24.585847854614258\n",
      "This is epoch   86\n",
      "Batch:  668/ 668 loss: 1026.4802 total time:  2.22s\n",
      "Training set\n",
      "weight = 1, err = 23.885305404663086\n",
      "Testing set\n",
      "weight = 1, err = 24.564777374267578\n",
      "This is epoch   87\n",
      "Batch:  668/ 668 loss: 1022.7688 total time:  2.14s\n",
      "Training set\n",
      "weight = 1, err = 23.750076293945312\n",
      "Testing set\n",
      "weight = 1, err = 24.395830154418945\n",
      "This is epoch   88\n",
      "Batch:  668/ 668 loss: 1019.7822 total time:  2.23s\n",
      "Training set\n",
      "weight = 1, err = 24.25107192993164\n",
      "Testing set\n",
      "weight = 1, err = 24.96654510498047\n",
      "This is epoch   89\n",
      "Batch:  668/ 668 loss: 1021.5218 total time:  2.10s\n",
      "Training set\n",
      "weight = 1, err = 23.80779457092285\n",
      "Testing set\n",
      "weight = 1, err = 24.596908569335938\n",
      "This is epoch   90\n",
      "Batch:  668/ 668 loss: 1020.3849 total time:  2.15s\n",
      "Training set\n",
      "weight = 1, err = 24.050838470458984\n",
      "Testing set\n",
      "weight = 1, err = 24.6774959564209\n",
      "This is epoch   91\n",
      "Batch:  668/ 668 loss: 1015.2637 total time:  2.08s\n",
      "Training set\n",
      "weight = 1, err = 23.631803512573242\n",
      "Testing set\n",
      "weight = 1, err = 24.372573852539062\n",
      "This is epoch   92\n",
      "Batch:  668/ 668 loss: 1012.7450 total time:  2.25s\n",
      "Training set\n",
      "weight = 1, err = 23.702436447143555\n",
      "Testing set\n",
      "weight = 1, err = 24.39984130859375\n",
      "This is epoch   93\n",
      "Batch:  668/ 668 loss: 1014.2309 total time:  2.12s\n",
      "Training set\n",
      "weight = 1, err = 24.289339065551758\n",
      "Testing set\n",
      "weight = 1, err = 24.921953201293945\n",
      "This is epoch   94\n",
      "Batch:  668/ 668 loss: 1006.6628 total time:  2.14s\n",
      "Training set\n",
      "weight = 1, err = 23.634641647338867\n",
      "Testing set\n",
      "weight = 1, err = 24.37144660949707\n",
      "This is epoch   95\n",
      "Batch:  668/ 668 loss: 1005.6733 total time:  2.05s\n",
      "Training set\n",
      "weight = 1, err = 24.090438842773438\n",
      "Testing set\n",
      "weight = 1, err = 24.931781768798828\n",
      "This is epoch   96\n",
      "Batch:  668/ 668 loss: 1005.9748 total time:  2.19s\n",
      "Training set\n",
      "weight = 1, err = 23.805830001831055\n",
      "Testing set\n",
      "weight = 1, err = 24.53331184387207\n",
      "This is epoch   97\n",
      "Batch:  668/ 668 loss: 1003.1479 total time:  2.21s\n",
      "Training set\n",
      "weight = 1, err = 23.56900978088379\n",
      "Testing set\n",
      "weight = 1, err = 24.301433563232422\n",
      "This is epoch   98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  668/ 668 loss: 1007.6492 total time:  2.02s\n",
      "Training set\n",
      "weight = 1, err = 23.627029418945312\n",
      "Testing set\n",
      "weight = 1, err = 24.35064697265625\n",
      "This is epoch   99\n",
      "Batch:  668/ 668 loss: 1000.0515 total time:  2.15s\n",
      "Training set\n",
      "weight = 1, err = 23.48772430419922\n",
      "Testing set\n",
      "weight = 1, err = 24.270801544189453\n",
      "This is epoch  100\n",
      "Batch:  668/ 668 loss: 995.3161 total time:  2.26s\n",
      "Training set\n",
      "weight = 1, err = 23.633363723754883\n",
      "Testing set\n",
      "weight = 1, err = 24.37457275390625\n",
      "This is epoch  101\n",
      "Batch:  668/ 668 loss: 995.1549 total time:  2.20s\n",
      "Training set\n",
      "weight = 1, err = 23.681865692138672\n",
      "Testing set\n",
      "weight = 1, err = 24.450166702270508\n",
      "This is epoch  102\n",
      "Batch:  668/ 668 loss: 995.0637 total time:  2.29s\n",
      "Training set\n",
      "weight = 1, err = 23.32610321044922\n",
      "Testing set\n",
      "weight = 1, err = 24.03675651550293\n",
      "This is epoch  103\n",
      "Batch:  668/ 668 loss: 998.8558 total time:  2.18s\n",
      "Training set\n",
      "weight = 1, err = 23.309810638427734\n",
      "Testing set\n",
      "weight = 1, err = 24.055341720581055\n",
      "This is epoch  104\n",
      "Batch:  668/ 668 loss: 994.7172 total time:  2.09s\n",
      "Training set\n",
      "weight = 1, err = 23.690223693847656\n",
      "Testing set\n",
      "weight = 1, err = 24.483951568603516\n",
      "This is epoch  105\n",
      "Batch:  668/ 668 loss: 993.7944 total time:  2.09s\n",
      "Training set\n",
      "weight = 1, err = 23.324134826660156\n",
      "Testing set\n",
      "weight = 1, err = 24.106306076049805\n",
      "This is epoch  106\n",
      "Batch:  668/ 668 loss: 986.6190 total time:  1.79s\n",
      "Training set\n",
      "weight = 1, err = 23.286182403564453\n",
      "Testing set\n",
      "weight = 1, err = 24.03125\n",
      "This is epoch  107\n",
      "Batch:  668/ 668 loss: 982.9609 total time:  2.21s\n",
      "Training set\n",
      "weight = 1, err = 23.40915298461914\n",
      "Testing set\n",
      "weight = 1, err = 24.16375732421875\n",
      "This is epoch  108\n",
      "Batch:  668/ 668 loss: 979.1465 total time:  2.14s\n",
      "Training set\n",
      "weight = 1, err = 23.345970153808594\n",
      "Testing set\n",
      "weight = 1, err = 24.12083625793457\n",
      "This is epoch  109\n",
      "Batch:  668/ 668 loss: 983.4313 total time:  2.26s\n",
      "Training set\n",
      "weight = 1, err = 23.45616912841797\n",
      "Testing set\n",
      "weight = 1, err = 24.205625534057617\n",
      "This is epoch  110\n",
      "Batch:  668/ 668 loss: 984.1108 total time:  2.27s\n",
      "Training set\n",
      "weight = 1, err = 23.184083938598633\n",
      "Testing set\n",
      "weight = 1, err = 23.93607521057129\n",
      "This is epoch  111\n",
      "Batch:  668/ 668 loss: 981.8643 total time:  2.11s\n",
      "Training set\n",
      "weight = 1, err = 23.509521484375\n",
      "Testing set\n",
      "weight = 1, err = 24.24757194519043\n",
      "This is epoch  112\n",
      "Batch:  668/ 668 loss: 978.1179 total time:  2.11s\n",
      "Training set\n",
      "weight = 1, err = 23.398693084716797\n",
      "Testing set\n",
      "weight = 1, err = 24.195785522460938\n",
      "This is epoch  113\n",
      "Batch:  668/ 668 loss: 975.9755 total time:  2.16s\n",
      "Training set\n",
      "weight = 1, err = 23.38791275024414\n",
      "Testing set\n",
      "weight = 1, err = 24.07737922668457\n",
      "This is epoch  114\n",
      "Batch:  668/ 668 loss: 974.3424 total time:  2.18s\n",
      "Training set\n",
      "weight = 1, err = 23.34060287475586\n",
      "Testing set\n",
      "weight = 1, err = 24.096742630004883\n",
      "This is epoch  115\n",
      "Batch:  668/ 668 loss: 969.5127 total time:  2.23s\n",
      "Training set\n",
      "weight = 1, err = 23.26982307434082\n",
      "Testing set\n",
      "weight = 1, err = 23.936201095581055\n",
      "This is epoch  116\n",
      "Batch:  668/ 668 loss: 971.5552 total time:  2.25s\n",
      "Training set\n",
      "weight = 1, err = 23.128742218017578\n",
      "Testing set\n",
      "weight = 1, err = 23.876201629638672\n",
      "This is epoch  117\n",
      "Batch:  668/ 668 loss: 976.6547 total time:  2.27s\n",
      "Training set\n",
      "weight = 1, err = 23.091541290283203\n",
      "Testing set\n",
      "weight = 1, err = 23.837265014648438\n",
      "This is epoch  118\n",
      "Batch:  668/ 668 loss: 971.7077 total time:  2.16s\n",
      "Training set\n",
      "weight = 1, err = 23.091140747070312\n",
      "Testing set\n",
      "weight = 1, err = 23.84952735900879\n",
      "This is epoch  119\n",
      "Batch:  668/ 668 loss: 972.7715 total time:  2.22s\n",
      "Training set\n",
      "weight = 1, err = 23.03382110595703\n",
      "Testing set\n",
      "weight = 1, err = 23.752662658691406\n",
      "This is epoch  120\n",
      "Batch:  668/ 668 loss: 970.9225 total time:  2.28s\n",
      "Training set\n",
      "weight = 1, err = 23.162580490112305\n",
      "Testing set\n",
      "weight = 1, err = 23.993825912475586\n",
      "This is epoch  121\n",
      "Batch:  668/ 668 loss: 962.8791 total time:  2.17s\n",
      "Training set\n",
      "weight = 1, err = 23.234630584716797\n",
      "Testing set\n",
      "weight = 1, err = 24.026273727416992\n",
      "This is epoch  122\n",
      "Batch:  668/ 668 loss: 957.7539 total time:  2.30s\n",
      "Training set\n",
      "weight = 1, err = 22.989665985107422\n",
      "Testing set\n",
      "weight = 1, err = 23.828439712524414\n",
      "This is epoch  123\n",
      "Batch:  668/ 668 loss: 957.9739 total time:  2.14s\n",
      "Training set\n",
      "weight = 1, err = 22.9509334564209\n",
      "Testing set\n",
      "weight = 1, err = 23.825109481811523\n",
      "This is epoch  124\n",
      "Batch:  668/ 668 loss: 958.8730 total time:  2.17s\n",
      "Training set\n",
      "weight = 1, err = 22.72988510131836\n",
      "Testing set\n",
      "weight = 1, err = 23.493764877319336\n",
      "This is epoch  125\n",
      "Batch:  668/ 668 loss: 962.7493 total time:  2.25s\n",
      "Training set\n",
      "weight = 1, err = 23.011693954467773\n",
      "Testing set\n",
      "weight = 1, err = 23.75286865234375\n",
      "This is epoch  126\n",
      "Batch:  668/ 668 loss: 958.2607 total time:  2.09s\n",
      "Training set\n",
      "weight = 1, err = 22.84770393371582\n",
      "Testing set\n",
      "weight = 1, err = 23.66808319091797\n",
      "This is epoch  127\n",
      "Batch:  668/ 668 loss: 952.8800 total time:  2.14s\n",
      "Training set\n",
      "weight = 1, err = 23.077495574951172\n",
      "Testing set\n",
      "weight = 1, err = 23.755067825317383\n",
      "This is epoch  128\n",
      "Batch:  668/ 668 loss: 952.8874 total time:  2.19s\n",
      "Training set\n",
      "weight = 1, err = 22.97393798828125\n",
      "Testing set\n",
      "weight = 1, err = 23.6713809967041\n",
      "This is epoch  129\n",
      "Batch:  668/ 668 loss: 951.7184 total time:  2.08s\n",
      "Training set\n",
      "weight = 1, err = 22.843399047851562\n",
      "Testing set\n",
      "weight = 1, err = 23.602033615112305\n",
      "This is epoch  130\n",
      "Batch:  668/ 668 loss: 949.0247 total time:  2.01s\n",
      "Training set\n",
      "weight = 1, err = 22.796676635742188\n",
      "Testing set\n",
      "weight = 1, err = 23.55881118774414\n",
      "This is epoch  131\n",
      "Batch:  668/ 668 loss: 953.9006 total time:  2.08s\n",
      "Training set\n",
      "weight = 1, err = 22.757713317871094\n",
      "Testing set\n",
      "weight = 1, err = 23.4936580657959\n",
      "This is epoch  132\n",
      "Batch:  668/ 668 loss: 948.4267 total time:  2.15s\n",
      "Training set\n",
      "weight = 1, err = 22.57012367248535\n",
      "Testing set\n",
      "weight = 1, err = 23.375873565673828\n",
      "This is epoch  133\n",
      "Batch:  668/ 668 loss: 949.6479 total time:  2.06s\n",
      "Training set\n",
      "weight = 1, err = 22.6250057220459\n",
      "Testing set\n",
      "weight = 1, err = 23.382631301879883\n",
      "This is epoch  134\n",
      "Batch:  668/ 668 loss: 944.5361 total time:  2.29s\n",
      "Training set\n",
      "weight = 1, err = 22.936445236206055\n",
      "Testing set\n",
      "weight = 1, err = 23.68282127380371\n",
      "This is epoch  135\n",
      "Batch:  668/ 668 loss: 944.8796 total time:  2.20s\n",
      "Training set\n",
      "weight = 1, err = 22.499908447265625\n",
      "Testing set\n",
      "weight = 1, err = 23.317821502685547\n",
      "This is epoch  136\n",
      "Batch:  668/ 668 loss: 939.3283 total time:  2.12s\n",
      "Training set\n",
      "weight = 1, err = 22.582731246948242\n",
      "Testing set\n",
      "weight = 1, err = 23.458009719848633\n",
      "This is epoch  137\n",
      "Batch:  668/ 668 loss: 940.6999 total time:  2.12s\n",
      "Training set\n",
      "weight = 1, err = 22.63506507873535\n",
      "Testing set\n",
      "weight = 1, err = 23.447324752807617\n",
      "This is epoch  138\n",
      "Batch:  668/ 668 loss: 940.9036 total time:  1.97s\n",
      "Training set\n",
      "weight = 1, err = 22.449068069458008\n",
      "Testing set\n",
      "weight = 1, err = 23.331130981445312\n",
      "This is epoch  139\n",
      "Batch:  668/ 668 loss: 941.6431 total time:  2.19s\n",
      "Training set\n",
      "weight = 1, err = 22.529165267944336\n",
      "Testing set\n",
      "weight = 1, err = 23.306442260742188\n",
      "This is epoch  140\n",
      "Batch:  668/ 668 loss: 941.0096 total time:  2.12s\n",
      "Training set\n",
      "weight = 1, err = 22.447799682617188\n",
      "Testing set\n",
      "weight = 1, err = 23.228641510009766\n",
      "This is epoch  141\n",
      "Batch:  668/ 668 loss: 935.7631 total time:  1.96s            \n",
      "Training set\n",
      "weight = 1, err = 22.624710083007812\n",
      "Testing set\n",
      "weight = 1, err = 23.54396629333496\n",
      "This is epoch  142\n",
      "Batch:  668/ 668 loss: 937.9678 total time:  2.12s\n",
      "Training set\n",
      "weight = 1, err = 23.335819244384766\n",
      "Testing set\n",
      "weight = 1, err = 24.029375076293945\n",
      "This is epoch  143\n",
      "Batch:  668/ 668 loss: 938.8070 total time:  2.13s\n",
      "Training set\n",
      "weight = 1, err = 22.469646453857422\n",
      "Testing set\n",
      "weight = 1, err = 23.321706771850586\n",
      "This is epoch  144\n",
      "Batch:  668/ 668 loss: 937.4837 total time:  2.14s\n",
      "Training set\n",
      "weight = 1, err = 22.469093322753906\n",
      "Testing set\n",
      "weight = 1, err = 23.34891700744629\n",
      "This is epoch  145\n",
      "Batch:  668/ 668 loss: 932.1946 total time:  2.11s\n",
      "Training set\n",
      "weight = 1, err = 22.57783317565918\n",
      "Testing set\n",
      "weight = 1, err = 23.45340347290039\n",
      "This is epoch  146\n",
      "Batch:  668/ 668 loss: 931.7603 total time:  2.23s\n",
      "Training set\n",
      "weight = 1, err = 22.525474548339844\n",
      "Testing set\n",
      "weight = 1, err = 23.393409729003906\n",
      "This is epoch  147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  668/ 668 loss: 930.1058 total time:  1.94s\n",
      "Training set\n",
      "weight = 1, err = 22.33863067626953\n",
      "Testing set\n",
      "weight = 1, err = 23.183486938476562\n",
      "This is epoch  148\n",
      "Batch:  668/ 668 loss: 931.2269 total time:  2.18s\n",
      "Training set\n",
      "weight = 1, err = 23.17204475402832\n",
      "Testing set\n",
      "weight = 1, err = 24.09731674194336\n",
      "This is epoch  149\n",
      "Batch:  668/ 668 loss: 931.2129 total time:  2.25s\n",
      "Training set\n",
      "weight = 1, err = 22.22264862060547\n",
      "Testing set\n",
      "weight = 1, err = 23.084192276000977\n",
      "This is epoch  150\n",
      "Batch:  668/ 668 loss: 919.9751 total time:  2.21s\n",
      "Training set\n",
      "weight = 1, err = 22.467695236206055\n",
      "Testing set\n",
      "weight = 1, err = 23.252920150756836\n",
      "This is epoch  151\n",
      "Batch:  668/ 668 loss: 925.8775 total time:  2.16s\n",
      "Training set\n",
      "weight = 1, err = 22.264808654785156\n",
      "Testing set\n",
      "weight = 1, err = 23.054012298583984\n",
      "This is epoch  152\n",
      "Batch:  668/ 668 loss: 924.4024 total time:  2.17s\n",
      "Training set\n",
      "weight = 1, err = 22.458860397338867\n",
      "Testing set\n",
      "weight = 1, err = 23.304777145385742\n",
      "This is epoch  153\n",
      "Batch:  668/ 668 loss: 922.9748 total time:  2.27s\n",
      "Training set\n",
      "weight = 1, err = 22.93027114868164\n",
      "Testing set\n",
      "weight = 1, err = 23.725034713745117\n",
      "This is epoch  154\n",
      "Batch:  668/ 668 loss: 920.9360 total time:  2.14s\n",
      "Training set\n",
      "weight = 1, err = 22.428302764892578\n",
      "Testing set\n",
      "weight = 1, err = 23.28061294555664\n",
      "This is epoch  155\n",
      "Batch:  668/ 668 loss: 921.1174 total time:  2.17s\n",
      "Training set\n",
      "weight = 1, err = 22.307247161865234\n",
      "Testing set\n",
      "weight = 1, err = 23.180561065673828\n",
      "This is epoch  156\n",
      "Batch:  668/ 668 loss: 911.3171 total time:  2.19s\n",
      "Training set\n",
      "weight = 1, err = 22.37784194946289\n",
      "Testing set\n",
      "weight = 1, err = 23.256322860717773\n",
      "This is epoch  157\n",
      "Batch:  668/ 668 loss: 919.3713 total time:  2.20s\n",
      "Training set\n",
      "weight = 1, err = 22.18886375427246\n",
      "Testing set\n",
      "weight = 1, err = 23.080841064453125\n",
      "This is epoch  158\n",
      "Batch:  668/ 668 loss: 913.8145 total time:  2.15s\n",
      "Training set\n",
      "weight = 1, err = 22.221101760864258\n",
      "Testing set\n",
      "weight = 1, err = 23.016143798828125\n",
      "This is epoch  159\n",
      "Batch:  668/ 668 loss: 914.4895 total time:  2.26s\n",
      "Training set\n",
      "weight = 1, err = 22.06426429748535\n",
      "Testing set\n",
      "weight = 1, err = 22.992664337158203\n",
      "This is epoch  160\n",
      "Batch:  668/ 668 loss: 909.9787 total time:  2.12s\n",
      "Training set\n",
      "weight = 1, err = 22.506183624267578\n",
      "Testing set\n",
      "weight = 1, err = 23.294391632080078\n",
      "This is epoch  161\n",
      "Batch:  668/ 668 loss: 913.7730 total time:  2.30s\n",
      "Training set\n",
      "weight = 1, err = 22.112136840820312\n",
      "Testing set\n",
      "weight = 1, err = 22.986021041870117\n",
      "This is epoch  162\n",
      "Batch:  668/ 668 loss: 912.9258 total time:  2.40s\n",
      "Training set\n",
      "weight = 1, err = 22.604202270507812\n",
      "Testing set\n",
      "weight = 1, err = 23.562658309936523\n",
      "This is epoch  163\n",
      "Batch:  668/ 668 loss: 915.6632 total time:  2.37s\n",
      "Training set\n",
      "weight = 1, err = 22.143756866455078\n",
      "Testing set\n",
      "weight = 1, err = 23.08712387084961\n",
      "This is epoch  164\n",
      "Batch:  668/ 668 loss: 908.3719 total time:  2.26s\n",
      "Training set\n",
      "weight = 1, err = 22.160797119140625\n",
      "Testing set\n",
      "weight = 1, err = 22.989120483398438\n",
      "This is epoch  165\n",
      "Batch:  668/ 668 loss: 907.1617 total time:  2.08s\n",
      "Training set\n",
      "weight = 1, err = 22.257125854492188\n",
      "Testing set\n",
      "weight = 1, err = 23.197900772094727\n",
      "This is epoch  166\n",
      "Batch:  668/ 668 loss: 905.0667 total time:  2.06s\n",
      "Training set\n",
      "weight = 1, err = 21.86949348449707\n",
      "Testing set\n",
      "weight = 1, err = 22.783803939819336\n",
      "This is epoch  167\n",
      "Batch:  668/ 668 loss: 902.6030 total time:  2.07s\n",
      "Training set\n",
      "weight = 1, err = 21.981325149536133\n",
      "Testing set\n",
      "weight = 1, err = 22.877918243408203\n",
      "This is epoch  168\n",
      "Batch:  668/ 668 loss: 905.5056 total time:  2.15s\n",
      "Training set\n",
      "weight = 1, err = 22.24726676940918\n",
      "Testing set\n",
      "weight = 1, err = 23.076004028320312\n",
      "This is epoch  169\n",
      "Batch:  668/ 668 loss: 897.7855 total time:  2.13s\n",
      "Training set\n",
      "weight = 1, err = 22.006736755371094\n",
      "Testing set\n",
      "weight = 1, err = 22.90777015686035\n",
      "This is epoch  170\n",
      "Batch:  668/ 668 loss: 902.5267 total time:  2.10s\n",
      "Training set\n",
      "weight = 1, err = 22.064786911010742\n",
      "Testing set\n",
      "weight = 1, err = 22.8956356048584\n",
      "This is epoch  171\n",
      "Batch:  668/ 668 loss: 903.7749 total time:  2.05s\n",
      "Training set\n",
      "weight = 1, err = 21.829147338867188\n",
      "Testing set\n",
      "weight = 1, err = 22.751951217651367\n",
      "This is epoch  172\n",
      "Batch:  668/ 668 loss: 900.2417 total time:  2.09s\n",
      "Training set\n",
      "weight = 1, err = 21.915428161621094\n",
      "Testing set\n",
      "weight = 1, err = 22.86700439453125\n",
      "This is epoch  173\n",
      "Batch:  668/ 668 loss: 900.7343 total time:  1.99s\n",
      "Training set\n",
      "weight = 1, err = 21.831159591674805\n",
      "Testing set\n",
      "weight = 1, err = 22.786022186279297\n",
      "This is epoch  174\n",
      "Batch:  668/ 668 loss: 893.0009 total time:  2.25s\n",
      "Training set\n",
      "weight = 1, err = 21.850690841674805\n",
      "Testing set\n",
      "weight = 1, err = 22.785619735717773\n",
      "This is epoch  175\n",
      "Batch:  668/ 668 loss: 894.7622 total time:  2.21s\n",
      "Training set\n",
      "weight = 1, err = 22.173933029174805\n",
      "Testing set\n",
      "weight = 1, err = 23.174654006958008\n",
      "This is epoch  176\n",
      "Batch:  668/ 668 loss: 891.7879 total time:  2.09s\n",
      "Training set\n",
      "weight = 1, err = 21.840362548828125\n",
      "Testing set\n",
      "weight = 1, err = 22.776357650756836\n",
      "This is epoch  177\n",
      "Batch:  668/ 668 loss: 891.5988 total time:  2.23s\n",
      "Training set\n",
      "weight = 1, err = 21.759700775146484\n",
      "Testing set\n",
      "weight = 1, err = 22.713537216186523\n",
      "This is epoch  178\n",
      "Batch:  668/ 668 loss: 891.1110 total time:  2.21s\n",
      "Training set\n",
      "weight = 1, err = 21.782590866088867\n",
      "Testing set\n",
      "weight = 1, err = 22.750011444091797\n",
      "This is epoch  179\n",
      "Batch:  668/ 668 loss: 892.3393 total time:  2.13s\n",
      "Training set\n",
      "weight = 1, err = 22.260847091674805\n",
      "Testing set\n",
      "weight = 1, err = 23.16185760498047\n",
      "This is epoch  180\n",
      "Batch:  668/ 668 loss: 896.6375 total time:  2.12s\n",
      "Training set\n",
      "weight = 1, err = 21.713594436645508\n",
      "Testing set\n",
      "weight = 1, err = 22.71457290649414\n",
      "This is epoch  181\n",
      "Batch:  668/ 668 loss: 886.2310 total time:  2.11s\n",
      "Training set\n",
      "weight = 1, err = 21.72995376586914\n",
      "Testing set\n",
      "weight = 1, err = 22.78248405456543\n",
      "This is epoch  182\n",
      "Batch:  668/ 668 loss: 884.8879 total time:  2.22s\n",
      "Training set\n",
      "weight = 1, err = 21.688947677612305\n",
      "Testing set\n",
      "weight = 1, err = 22.750883102416992\n",
      "This is epoch  183\n",
      "Batch:  668/ 668 loss: 883.5338 total time:  2.20s\n",
      "Training set\n",
      "weight = 1, err = 22.049137115478516\n",
      "Testing set\n",
      "weight = 1, err = 23.024507522583008\n",
      "This is epoch  184\n",
      "Batch:  668/ 668 loss: 884.2560 total time:  2.18s\n",
      "Training set\n",
      "weight = 1, err = 21.65371322631836\n",
      "Testing set\n",
      "weight = 1, err = 22.678380966186523\n",
      "This is epoch  185\n",
      "Batch:  668/ 668 loss: 882.8814 total time:  2.23s\n",
      "Training set\n",
      "weight = 1, err = 21.672273635864258\n",
      "Testing set\n",
      "weight = 1, err = 22.633201599121094\n",
      "This is epoch  186\n",
      "Batch:  668/ 668 loss: 881.8212 total time:  2.10s\n",
      "Training set\n",
      "weight = 1, err = 22.067089080810547\n",
      "Testing set\n",
      "weight = 1, err = 22.993526458740234\n",
      "This is epoch  187\n",
      "Batch:  668/ 668 loss: 877.2639 total time:  2.14s\n",
      "Training set\n",
      "weight = 1, err = 21.777170181274414\n",
      "Testing set\n",
      "weight = 1, err = 22.75345230102539\n",
      "This is epoch  188\n",
      "Batch:  668/ 668 loss: 883.5449 total time:  2.09s\n",
      "Training set\n",
      "weight = 1, err = 21.84176254272461\n",
      "Testing set\n",
      "weight = 1, err = 22.839113235473633\n",
      "This is epoch  189\n",
      "Batch:  668/ 668 loss: 877.6098 total time:  2.10s\n",
      "Training set\n",
      "weight = 1, err = 21.874610900878906\n",
      "Testing set\n",
      "weight = 1, err = 22.81475257873535\n",
      "This is epoch  190\n",
      "Batch:  668/ 668 loss: 873.5455 total time:  2.13s\n",
      "Training set\n",
      "weight = 1, err = 22.17437171936035\n",
      "Testing set\n",
      "weight = 1, err = 23.1954345703125\n",
      "This is epoch  191\n",
      "Batch:  668/ 668 loss: 874.7141 total time:  2.10s\n",
      "Training set\n",
      "weight = 1, err = 21.92259979248047\n",
      "Testing set\n",
      "weight = 1, err = 22.833383560180664\n",
      "This is epoch  192\n",
      "Batch:  668/ 668 loss: 877.6646 total time:  2.28s\n",
      "Training set\n",
      "weight = 1, err = 21.82179832458496\n",
      "Testing set\n",
      "weight = 1, err = 22.832366943359375\n",
      "This is epoch  193\n",
      "Batch:  668/ 668 loss: 869.6190 total time:  2.09s\n",
      "Training set\n",
      "weight = 1, err = 21.65703582763672\n",
      "Testing set\n",
      "weight = 1, err = 22.654691696166992\n",
      "This is epoch  194\n",
      "Batch:  668/ 668 loss: 873.8573 total time:  2.05s\n",
      "Training set\n",
      "weight = 1, err = 21.39600372314453\n",
      "Testing set\n",
      "weight = 1, err = 22.40045738220215\n",
      "This is epoch  195\n",
      "Batch:  668/ 668 loss: 867.6811 total time:  2.12s\n",
      "Training set\n",
      "weight = 1, err = 21.527910232543945\n",
      "Testing set\n",
      "weight = 1, err = 22.437599182128906\n",
      "This is epoch  196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  668/ 668 loss: 878.3420 total time:  2.10s\n",
      "Training set\n",
      "weight = 1, err = 21.689136505126953\n",
      "Testing set\n",
      "weight = 1, err = 22.662845611572266\n",
      "This is epoch  197\n",
      "Batch:  668/ 668 loss: 867.9408 total time:  2.23s\n",
      "Training set\n",
      "weight = 1, err = 21.37213706970215\n",
      "Testing set\n",
      "weight = 1, err = 22.372461318969727\n",
      "This is epoch  198\n",
      "Batch:  668/ 668 loss: 878.6323 total time:  2.21s\n",
      "Training set\n",
      "weight = 1, err = 22.592538833618164\n",
      "Testing set\n",
      "weight = 1, err = 23.617095947265625\n",
      "This is epoch  199\n",
      "Batch:  668/ 668 loss: 867.6146 total time:  2.12s\n",
      "Training set\n",
      "weight = 1, err = 21.41990852355957\n",
      "Testing set\n",
      "weight = 1, err = 22.370479583740234\n",
      "This is epoch  200\n",
      "Batch:  668/ 668 loss: 866.4228 total time:  2.21s\n",
      "Training set\n",
      "weight = 1, err = 21.343830108642578\n",
      "Testing set\n",
      "weight = 1, err = 22.324434280395508\n",
      "This is epoch  201\n",
      "Batch:  668/ 668 loss: 865.8354 total time:  2.16s\n",
      "Training set\n",
      "weight = 1, err = 21.420055389404297\n",
      "Testing set\n",
      "weight = 1, err = 22.4309139251709\n",
      "This is epoch  202\n",
      "Batch:  668/ 668 loss: 860.9753 total time:  1.92s\n",
      "Training set\n",
      "weight = 1, err = 21.206939697265625\n",
      "Testing set\n",
      "weight = 1, err = 22.222455978393555\n",
      "This is epoch  203\n",
      "Batch:  668/ 668 loss: 859.3449 total time:  2.62s\n",
      "Training set\n",
      "weight = 1, err = 21.69682502746582\n",
      "Testing set\n",
      "weight = 1, err = 22.660049438476562\n",
      "This is epoch  204\n",
      "Batch:  668/ 668 loss: 860.8927 total time:  2.42s\n",
      "Training set\n",
      "weight = 1, err = 21.49112892150879\n",
      "Testing set\n",
      "weight = 1, err = 22.489337921142578\n",
      "This is epoch  205\n",
      "Batch:  668/ 668 loss: 854.8020 total time:  2.49s\n",
      "Training set\n",
      "weight = 1, err = 21.36329460144043\n",
      "Testing set\n",
      "weight = 1, err = 22.351179122924805\n",
      "This is epoch  206\n",
      "Batch:  668/ 668 loss: 858.5442 total time:  2.51s\n",
      "Training set\n",
      "weight = 1, err = 21.528839111328125\n",
      "Testing set\n",
      "weight = 1, err = 22.567930221557617\n",
      "This is epoch  207\n",
      "Batch:  668/ 668 loss: 856.7127 total time:  2.30s\n",
      "Training set\n",
      "weight = 1, err = 21.199853897094727\n",
      "Testing set\n",
      "weight = 1, err = 22.26209831237793\n",
      "This is epoch  208\n",
      "Batch:  668/ 668 loss: 849.2169 total time:  2.29s\n",
      "Training set\n",
      "weight = 1, err = 21.513229370117188\n",
      "Testing set\n",
      "weight = 1, err = 22.531742095947266\n",
      "This is epoch  209\n",
      "Batch:  668/ 668 loss: 858.3953 total time:  2.18s\n",
      "Training set\n",
      "weight = 1, err = 21.13241195678711\n",
      "Testing set\n",
      "weight = 1, err = 22.171918869018555\n",
      "This is epoch  210\n",
      "Batch:  668/ 668 loss: 852.0511 total time:  2.22s\n",
      "Training set\n",
      "weight = 1, err = 21.428796768188477\n",
      "Testing set\n",
      "weight = 1, err = 22.411365509033203\n",
      "This is epoch  211\n",
      "Batch:  668/ 668 loss: 859.5271 total time:  1.87s\n",
      "Training set\n",
      "weight = 1, err = 21.299968719482422\n",
      "Testing set\n",
      "weight = 1, err = 22.240846633911133\n",
      "This is epoch  212\n",
      "Batch:  668/ 668 loss: 854.1126 total time:  2.22s\n",
      "Training set\n",
      "weight = 1, err = 21.197681427001953\n",
      "Testing set\n",
      "weight = 1, err = 22.266761779785156\n",
      "This is epoch  213\n",
      "Batch:  668/ 668 loss: 841.3322 total time:  2.17s\n",
      "Training set\n",
      "weight = 1, err = 21.378286361694336\n",
      "Testing set\n",
      "weight = 1, err = 22.449100494384766\n",
      "This is epoch  214\n",
      "Batch:  668/ 668 loss: 850.0208 total time:  2.11s\n",
      "Training set\n",
      "weight = 1, err = 21.434825897216797\n",
      "Testing set\n",
      "weight = 1, err = 22.50432586669922\n",
      "This is epoch  215\n",
      "Batch:  668/ 668 loss: 846.5830 total time:  2.32s\n",
      "Training set\n",
      "weight = 1, err = 21.271812438964844\n",
      "Testing set\n",
      "weight = 1, err = 22.20912742614746\n",
      "This is epoch  216\n",
      "Batch:  668/ 668 loss: 846.0845 total time:  2.21s\n",
      "Training set\n",
      "weight = 1, err = 21.233501434326172\n",
      "Testing set\n",
      "weight = 1, err = 22.280717849731445\n",
      "This is epoch  217\n",
      "Batch:  668/ 668 loss: 843.4976 total time:  2.21s\n",
      "Training set\n",
      "weight = 1, err = 21.86663055419922\n",
      "Testing set\n",
      "weight = 1, err = 22.752370834350586\n",
      "This is epoch  218\n",
      "Batch:  668/ 668 loss: 845.7209 total time:  2.15s\n",
      "Training set\n",
      "weight = 1, err = 21.437179565429688\n",
      "Testing set\n",
      "weight = 1, err = 22.413646697998047\n",
      "This is epoch  219\n",
      "Batch:  668/ 668 loss: 842.6063 total time:  2.13s\n",
      "Training set\n",
      "weight = 1, err = 20.874889373779297\n",
      "Testing set\n",
      "weight = 1, err = 21.934673309326172\n",
      "This is epoch  220\n",
      "Batch:  668/ 668 loss: 838.2345 total time:  2.35s\n",
      "Training set\n",
      "weight = 1, err = 21.224241256713867\n",
      "Testing set\n",
      "weight = 1, err = 22.217065811157227\n",
      "This is epoch  221\n",
      "Batch:  668/ 668 loss: 836.9155 total time:  2.23s\n",
      "Training set\n",
      "weight = 1, err = 21.217782974243164\n",
      "Testing set\n",
      "weight = 1, err = 22.14610481262207\n",
      "This is epoch  222\n",
      "Batch:  668/ 668 loss: 836.6142 total time:  2.16s\n",
      "Training set\n",
      "weight = 1, err = 20.909378051757812\n",
      "Testing set\n",
      "weight = 1, err = 21.9036922454834\n",
      "This is epoch  223\n",
      "Batch:  668/ 668 loss: 832.6804 total time:  2.18s\n",
      "Training set\n",
      "weight = 1, err = 20.84214973449707\n",
      "Testing set\n",
      "weight = 1, err = 21.912397384643555\n",
      "This is epoch  224\n",
      "Batch:  668/ 668 loss: 827.8187 total time:  2.36s\n",
      "Training set\n",
      "weight = 1, err = 20.99262046813965\n",
      "Testing set\n",
      "weight = 1, err = 22.01011085510254\n",
      "This is epoch  225\n",
      "Batch:  668/ 668 loss: 834.3891 total time:  2.29s\n",
      "Training set\n",
      "weight = 1, err = 20.830848693847656\n",
      "Testing set\n",
      "weight = 1, err = 21.76718521118164\n",
      "This is epoch  226\n",
      "Batch:  668/ 668 loss: 829.6988 total time:  2.29s\n",
      "Training set\n",
      "weight = 1, err = 21.01378631591797\n",
      "Testing set\n",
      "weight = 1, err = 22.03560447692871\n",
      "This is epoch  227\n",
      "Batch:  668/ 668 loss: 827.3799 total time:  2.36s\n",
      "Training set\n",
      "weight = 1, err = 20.630359649658203\n",
      "Testing set\n",
      "weight = 1, err = 21.677751541137695\n",
      "This is epoch  228\n",
      "Batch:  668/ 668 loss: 826.6206 total time:  2.20s\n",
      "Training set\n",
      "weight = 1, err = 20.852859497070312\n",
      "Testing set\n",
      "weight = 1, err = 21.807069778442383\n",
      "This is epoch  229\n",
      "Batch:  668/ 668 loss: 825.7167 total time:  2.20s\n",
      "Training set\n",
      "weight = 1, err = 20.70082664489746\n",
      "Testing set\n",
      "weight = 1, err = 21.704761505126953\n",
      "This is epoch  230\n",
      "Batch:  668/ 668 loss: 825.1962 total time:  2.29s\n",
      "Training set\n",
      "weight = 1, err = 20.594419479370117\n",
      "Testing set\n",
      "weight = 1, err = 21.596405029296875\n",
      "This is epoch  231\n",
      "Batch:  668/ 668 loss: 824.2040 total time:  2.23s\n",
      "Training set\n",
      "weight = 1, err = 21.267667770385742\n",
      "Testing set\n",
      "weight = 1, err = 22.223594665527344\n",
      "This is epoch  232\n",
      "Batch:  668/ 668 loss: 820.9021 total time:  2.28s\n",
      "Training set\n",
      "weight = 1, err = 20.74564552307129\n",
      "Testing set\n",
      "weight = 1, err = 21.781692504882812\n",
      "This is epoch  233\n",
      "Batch:  668/ 668 loss: 821.6780 total time:  2.21s\n",
      "Training set\n",
      "weight = 1, err = 20.87032127380371\n",
      "Testing set\n",
      "weight = 1, err = 21.77821159362793\n",
      "This is epoch  234\n",
      "Batch:  668/ 668 loss: 817.8708 total time:  2.03s\n",
      "Training set\n",
      "weight = 1, err = 20.511507034301758\n",
      "Testing set\n",
      "weight = 1, err = 21.513465881347656\n",
      "This is epoch  235\n",
      "Batch:  668/ 668 loss: 818.1009 total time:  2.21s\n",
      "Training set\n",
      "weight = 1, err = 20.50421714782715\n",
      "Testing set\n",
      "weight = 1, err = 21.545738220214844\n",
      "This is epoch  236\n",
      "Batch:  668/ 668 loss: 818.0722 total time:  2.31s\n",
      "Training set\n",
      "weight = 1, err = 20.649911880493164\n",
      "Testing set\n",
      "weight = 1, err = 21.637237548828125\n",
      "This is epoch  237\n",
      "Batch:  668/ 668 loss: 816.1495 total time:  2.22s\n",
      "Training set\n",
      "weight = 1, err = 20.604616165161133\n",
      "Testing set\n",
      "weight = 1, err = 21.58030891418457\n",
      "This is epoch  238\n",
      "Batch:  668/ 668 loss: 823.2329 total time:  2.21s\n",
      "Training set\n",
      "weight = 1, err = 20.881986618041992\n",
      "Testing set\n",
      "weight = 1, err = 21.91330909729004\n",
      "This is epoch  239\n",
      "Batch:  668/ 668 loss: 821.5876 total time:  2.12s\n",
      "Training set\n",
      "weight = 1, err = 20.489994049072266\n",
      "Testing set\n",
      "weight = 1, err = 21.510591506958008\n",
      "This is epoch  240\n",
      "Batch:  668/ 668 loss: 813.3308 total time:  2.08s\n",
      "Training set\n",
      "weight = 1, err = 20.57681655883789\n",
      "Testing set\n",
      "weight = 1, err = 21.576683044433594\n",
      "This is epoch  241\n",
      "Batch:  668/ 668 loss: 807.6078 total time:  2.15s\n",
      "Training set\n",
      "weight = 1, err = 20.645137786865234\n",
      "Testing set\n",
      "weight = 1, err = 21.54437828063965\n",
      "This is epoch  242\n",
      "Batch:  668/ 668 loss: 813.0533 total time:  2.27s\n",
      "Training set\n",
      "weight = 1, err = 20.3974552154541\n",
      "Testing set\n",
      "weight = 1, err = 21.342191696166992\n",
      "This is epoch  243\n",
      "Batch:  668/ 668 loss: 807.2900 total time:  2.21s\n",
      "Training set\n",
      "weight = 1, err = 20.38897132873535\n",
      "Testing set\n",
      "weight = 1, err = 21.379091262817383\n",
      "This is epoch  244\n",
      "Batch:  668/ 668 loss: 814.4507 total time:  1.68s\n",
      "Training set\n",
      "weight = 1, err = 20.513309478759766\n",
      "Testing set\n",
      "weight = 1, err = 21.436155319213867\n",
      "This is epoch  245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  668/ 668 loss: 807.5712 total time:  1.68s\n",
      "Training set\n",
      "weight = 1, err = 21.795042037963867\n",
      "Testing set\n",
      "weight = 1, err = 22.616575241088867\n",
      "This is epoch  246\n",
      "Batch:  668/ 668 loss: 810.0256 total time:  2.06s\n",
      "Training set\n",
      "weight = 1, err = 20.61138153076172\n",
      "Testing set\n",
      "weight = 1, err = 21.546056747436523\n",
      "This is epoch  247\n",
      "Batch:  668/ 668 loss: 806.6941 total time:  2.13s\n",
      "Training set\n",
      "weight = 1, err = 20.193376541137695\n",
      "Testing set\n",
      "weight = 1, err = 21.196552276611328\n",
      "This is epoch  248\n",
      "Batch:  668/ 668 loss: 798.0346 total time:  2.28s\n",
      "Training set\n",
      "weight = 1, err = 20.353376388549805\n",
      "Testing set\n",
      "weight = 1, err = 21.390623092651367\n",
      "This is epoch  249\n",
      "Batch:  668/ 668 loss: 808.0865 total time:  2.20s\n",
      "Training set\n",
      "weight = 1, err = 20.198957443237305\n",
      "Testing set\n",
      "weight = 1, err = 21.13668441772461\n",
      "This is epoch  250\n",
      "Batch:  668/ 668 loss: 799.3393 total time:  2.29s\n",
      "Training set\n",
      "weight = 1, err = 21.093162536621094\n",
      "Testing set\n",
      "weight = 1, err = 22.05335235595703\n",
      "This is epoch  251\n",
      "Batch:  668/ 668 loss: 800.7956 total time:  2.11s\n",
      "Training set\n",
      "weight = 1, err = 20.243919372558594\n",
      "Testing set\n",
      "weight = 1, err = 21.186920166015625\n",
      "This is epoch  252\n",
      "Batch:  668/ 668 loss: 796.1806 total time:  2.18s\n",
      "Training set\n",
      "weight = 1, err = 20.47577476501465\n",
      "Testing set\n",
      "weight = 1, err = 21.50581932067871\n",
      "This is epoch  253\n",
      "Batch:  668/ 668 loss: 798.5270 total time:  2.12s\n",
      "Training set\n",
      "weight = 1, err = 20.227725982666016\n",
      "Testing set\n",
      "weight = 1, err = 21.24239730834961\n",
      "This is epoch  254\n",
      "Batch:  668/ 668 loss: 795.3705 total time:  2.23s\n",
      "Training set\n",
      "weight = 1, err = 20.13212013244629\n",
      "Testing set\n",
      "weight = 1, err = 21.107995986938477\n",
      "This is epoch  255\n",
      "Batch:  668/ 668 loss: 793.9403 total time:  2.24s\n",
      "Training set\n",
      "weight = 1, err = 20.474803924560547\n",
      "Testing set\n",
      "weight = 1, err = 21.34695816040039\n",
      "This is epoch  256\n",
      "Batch:  668/ 668 loss: 797.7167 total time:  2.25s\n",
      "Training set\n",
      "weight = 1, err = 20.388935089111328\n",
      "Testing set\n",
      "weight = 1, err = 21.40402603149414\n",
      "This is epoch  257\n",
      "Batch:  668/ 668 loss: 797.2358 total time:  2.08s\n",
      "Training set\n",
      "weight = 1, err = 20.56899070739746\n",
      "Testing set\n",
      "weight = 1, err = 21.47195053100586\n",
      "This is epoch  258\n",
      "Batch:  668/ 668 loss: 798.5729 total time:  2.16s\n",
      "Training set\n",
      "weight = 1, err = 20.255260467529297\n",
      "Testing set\n",
      "weight = 1, err = 21.26922035217285\n",
      "This is epoch  259\n",
      "Batch:  668/ 668 loss: 788.3410 total time:  2.15s\n",
      "Training set\n",
      "weight = 1, err = 20.006404876708984\n",
      "Testing set\n",
      "weight = 1, err = 21.027732849121094\n",
      "This is epoch  260\n",
      "Batch:  668/ 668 loss: 792.2027 total time:  2.26s\n",
      "Training set\n",
      "weight = 1, err = 20.005197525024414\n",
      "Testing set\n",
      "weight = 1, err = 21.011219024658203\n",
      "This is epoch  261\n",
      "Batch:  668/ 668 loss: 792.4371 total time:  2.41s\n",
      "Training set\n",
      "weight = 1, err = 20.1456298828125\n",
      "Testing set\n",
      "weight = 1, err = 21.142852783203125\n",
      "This is epoch  262\n",
      "Batch:  668/ 668 loss: 787.1935 total time:  2.39s\n",
      "Training set\n",
      "weight = 1, err = 20.380535125732422\n",
      "Testing set\n",
      "weight = 1, err = 21.318267822265625\n",
      "This is epoch  263\n",
      "Batch:  668/ 668 loss: 790.2999 total time:  2.19s\n",
      "Training set\n",
      "weight = 1, err = 19.922922134399414\n",
      "Testing set\n",
      "weight = 1, err = 20.91021156311035\n",
      "This is epoch  264\n",
      "Batch:  668/ 668 loss: 788.3831 total time:  2.13s\n",
      "Training set\n",
      "weight = 1, err = 19.97235870361328\n",
      "Testing set\n",
      "weight = 1, err = 20.97229766845703\n",
      "This is epoch  265\n",
      "Batch:  668/ 668 loss: 785.8672 total time:  2.10s\n",
      "Training set\n",
      "weight = 1, err = 19.82514190673828\n",
      "Testing set\n",
      "weight = 1, err = 20.933700561523438\n",
      "This is epoch  266\n",
      "Batch:  668/ 668 loss: 782.1041 total time:  2.17s\n",
      "Training set\n",
      "weight = 1, err = 19.9051513671875\n",
      "Testing set\n",
      "weight = 1, err = 20.9487247467041\n",
      "This is epoch  267\n",
      "Batch:  668/ 668 loss: 784.9589 total time:  2.27s\n",
      "Training set\n",
      "weight = 1, err = 20.75136375427246\n",
      "Testing set\n",
      "weight = 1, err = 21.803680419921875\n",
      "This is epoch  268\n",
      "Batch:  668/ 668 loss: 781.4688 total time:  2.20s\n",
      "Training set\n",
      "weight = 1, err = 20.044557571411133\n",
      "Testing set\n",
      "weight = 1, err = 21.084402084350586\n",
      "This is epoch  269\n",
      "Batch:  668/ 668 loss: 779.5624 total time:  2.24s\n",
      "Training set\n",
      "weight = 1, err = 19.829490661621094\n",
      "Testing set\n",
      "weight = 1, err = 20.842561721801758\n",
      "This is epoch  270\n",
      "Batch:  668/ 668 loss: 782.1122 total time:  2.13s\n",
      "Training set\n",
      "weight = 1, err = 20.081663131713867\n",
      "Testing set\n",
      "weight = 1, err = 21.047712326049805\n",
      "This is epoch  271\n",
      "Batch:  668/ 668 loss: 775.9700 total time:  2.11s\n",
      "Training set\n",
      "weight = 1, err = 20.027692794799805\n",
      "Testing set\n",
      "weight = 1, err = 21.088180541992188\n",
      "This is epoch  272\n",
      "Batch:  668/ 668 loss: 780.2556 total time:  2.12s\n",
      "Training set\n",
      "weight = 1, err = 20.101552963256836\n",
      "Testing set\n",
      "weight = 1, err = 21.17430305480957\n",
      "This is epoch  273\n",
      "Batch:  668/ 668 loss: 779.4292 total time:  2.11s\n",
      "Training set\n",
      "weight = 1, err = 20.2364444732666\n",
      "Testing set\n",
      "weight = 1, err = 21.289447784423828\n",
      "This is epoch  274\n",
      "Batch:  668/ 668 loss: 782.6544 total time:  2.27s\n",
      "Training set\n",
      "weight = 1, err = 20.50499725341797\n",
      "Testing set\n",
      "weight = 1, err = 21.546728134155273\n",
      "This is epoch  275\n",
      "Batch:  668/ 668 loss: 776.3494 total time:  2.15s\n",
      "Training set\n",
      "weight = 1, err = 19.77029037475586\n",
      "Testing set\n",
      "weight = 1, err = 20.85988426208496\n",
      "This is epoch  276\n",
      "Batch:  668/ 668 loss: 771.5795 total time:  2.20s\n",
      "Training set\n",
      "weight = 1, err = 19.893905639648438\n",
      "Testing set\n",
      "weight = 1, err = 20.905590057373047\n",
      "This is epoch  277\n",
      "Batch:  668/ 668 loss: 776.1446 total time:  2.15s\n",
      "Training set\n",
      "weight = 1, err = 19.783870697021484\n",
      "Testing set\n",
      "weight = 1, err = 20.817853927612305\n",
      "This is epoch  278\n",
      "Batch:  668/ 668 loss: 774.7659 total time:  2.32s\n",
      "Training set\n",
      "weight = 1, err = 20.006607055664062\n",
      "Testing set\n",
      "weight = 1, err = 21.099422454833984\n",
      "This is epoch  279\n",
      "Batch:  668/ 668 loss: 772.9561 total time:  2.23s\n",
      "Training set\n",
      "weight = 1, err = 19.99219512939453\n",
      "Testing set\n",
      "weight = 1, err = 21.029897689819336\n",
      "This is epoch  280\n",
      "Batch:  668/ 668 loss: 769.4385 total time:  2.18s\n",
      "Training set\n",
      "weight = 1, err = 19.688386917114258\n",
      "Testing set\n",
      "weight = 1, err = 20.688413619995117\n",
      "This is epoch  281\n",
      "Batch:  668/ 668 loss: 773.1524 total time:  2.21s\n",
      "Training set\n",
      "weight = 1, err = 19.670759201049805\n",
      "Testing set\n",
      "weight = 1, err = 20.6885929107666\n",
      "This is epoch  282\n",
      "Batch:  668/ 668 loss: 776.2683 total time:  2.09s\n",
      "Training set\n",
      "weight = 1, err = 19.714277267456055\n",
      "Testing set\n",
      "weight = 1, err = 20.801860809326172\n",
      "This is epoch  283\n",
      "Batch:  668/ 668 loss: 774.9986 total time:  2.11s\n",
      "Training set\n",
      "weight = 1, err = 19.69506072998047\n",
      "Testing set\n",
      "weight = 1, err = 20.72154998779297\n",
      "This is epoch  284\n",
      "Batch:  668/ 668 loss: 772.0377 total time:  2.27s\n",
      "Training set\n",
      "weight = 1, err = 19.98952865600586\n",
      "Testing set\n",
      "weight = 1, err = 21.089683532714844\n",
      "This is epoch  285\n",
      "Batch:  668/ 668 loss: 772.5642 total time:  2.45s\n",
      "Training set\n",
      "weight = 1, err = 19.804332733154297\n",
      "Testing set\n",
      "weight = 1, err = 20.808513641357422\n",
      "This is epoch  286\n",
      "Batch:  668/ 668 loss: 769.7869 total time:  2.36s\n",
      "Training set\n",
      "weight = 1, err = 19.83101463317871\n",
      "Testing set\n",
      "weight = 1, err = 20.937162399291992\n",
      "This is epoch  287\n",
      "Batch:  668/ 668 loss: 767.1859 total time:  2.19s\n",
      "Training set\n",
      "weight = 1, err = 19.624101638793945\n",
      "Testing set\n",
      "weight = 1, err = 20.68321418762207\n",
      "This is epoch  288\n",
      "Batch:  668/ 668 loss: 767.0197 total time:  2.20s\n",
      "Training set\n",
      "weight = 1, err = 19.576547622680664\n",
      "Testing set\n",
      "weight = 1, err = 20.62386131286621\n",
      "This is epoch  289\n",
      "Batch:  668/ 668 loss: 770.9932 total time:  2.12s\n",
      "Training set\n",
      "weight = 1, err = 19.934982299804688\n",
      "Testing set\n",
      "weight = 1, err = 20.97559356689453\n",
      "This is epoch  290\n",
      "Batch:  668/ 668 loss: 763.8063 total time:  2.04s\n",
      "Training set\n",
      "weight = 1, err = 20.07718849182129\n",
      "Testing set\n",
      "weight = 1, err = 21.129060745239258\n",
      "This is epoch  291\n",
      "Batch:  668/ 668 loss: 766.3393 total time:  2.20s\n",
      "Training set\n",
      "weight = 1, err = 19.675230026245117\n",
      "Testing set\n",
      "weight = 1, err = 20.809293746948242\n",
      "This is epoch  292\n",
      "Batch:  668/ 668 loss: 756.0020 total time:  2.15s\n",
      "Training set\n",
      "weight = 1, err = 19.67464828491211\n",
      "Testing set\n",
      "weight = 1, err = 20.752849578857422\n",
      "This is epoch  293\n",
      "Batch:  668/ 668 loss: 765.5521 total time:  2.12s\n",
      "Training set\n",
      "weight = 1, err = 20.25078582763672\n",
      "Testing set\n",
      "weight = 1, err = 21.156719207763672\n",
      "This is epoch  294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  668/ 668 loss: 762.8571 total time:  2.23s\n",
      "Training set\n",
      "weight = 1, err = 19.77886962890625\n",
      "Testing set\n",
      "weight = 1, err = 20.928260803222656\n",
      "This is epoch  295\n",
      "Batch:  668/ 668 loss: 764.1806 total time:  2.13s\n",
      "Training set\n",
      "weight = 1, err = 19.573747634887695\n",
      "Testing set\n",
      "weight = 1, err = 20.6766300201416\n",
      "This is epoch  296\n",
      "Batch:  668/ 668 loss: 762.5393 total time:  2.09s\n",
      "Training set\n",
      "weight = 1, err = 19.823598861694336\n",
      "Testing set\n",
      "weight = 1, err = 20.817977905273438\n",
      "This is epoch  297\n",
      "Batch:  668/ 668 loss: 764.8118 total time:  2.16s\n",
      "Training set\n",
      "weight = 1, err = 19.57356071472168\n",
      "Testing set\n",
      "weight = 1, err = 20.64868927001953\n",
      "This is epoch  298\n",
      "Batch:  668/ 668 loss: 762.4566 total time:  2.54s\n",
      "Training set\n",
      "weight = 1, err = 19.622936248779297\n",
      "Testing set\n",
      "weight = 1, err = 20.720918655395508\n",
      "This is epoch  299\n",
      "Batch:  668/ 668 loss: 760.3097 total time:  2.34s\n",
      "Training set\n",
      "weight = 1, err = 19.735458374023438\n",
      "Testing set\n",
      "weight = 1, err = 20.778179168701172\n",
      "This is epoch  300\n",
      "Batch:  668/ 668 loss: 762.7095 total time:  2.30s\n",
      "Training set\n",
      "weight = 1, err = 19.82443618774414\n",
      "Testing set\n",
      "weight = 1, err = 20.911195755004883\n",
      "This is epoch  301\n",
      "Batch:  668/ 668 loss: 759.7000 total time:  2.40s\n",
      "Training set\n",
      "weight = 1, err = 19.487834930419922\n",
      "Testing set\n",
      "weight = 1, err = 20.514114379882812\n",
      "This is epoch  302\n",
      "Batch:  668/ 668 loss: 760.9698 total time:  2.26s\n",
      "Training set\n",
      "weight = 1, err = 19.474140167236328\n",
      "Testing set\n",
      "weight = 1, err = 20.54600715637207\n",
      "This is epoch  303\n",
      "Batch:  668/ 668 loss: 756.6560 total time:  2.43s\n",
      "Training set\n",
      "weight = 1, err = 19.64192008972168\n",
      "Testing set\n",
      "weight = 1, err = 20.66371726989746\n",
      "This is epoch  304\n",
      "Batch:  668/ 668 loss: 754.5737 total time:  2.28s\n",
      "Training set\n",
      "weight = 1, err = 19.460420608520508\n",
      "Testing set\n",
      "weight = 1, err = 20.51732635498047\n",
      "This is epoch  305\n",
      "Batch:  668/ 668 loss: 756.0329 total time:  2.49s\n",
      "Training set\n",
      "weight = 1, err = 19.63249969482422\n",
      "Testing set\n",
      "weight = 1, err = 20.716503143310547\n",
      "This is epoch  306\n",
      "Batch:  668/ 668 loss: 756.1688 total time:  2.49s\n",
      "Training set\n",
      "weight = 1, err = 19.687402725219727\n",
      "Testing set\n",
      "weight = 1, err = 20.83076286315918\n",
      "This is epoch  307\n",
      "Batch:  668/ 668 loss: 750.8608 total time:  1.80s\n",
      "Training set\n",
      "weight = 1, err = 19.410747528076172\n",
      "Testing set\n",
      "weight = 1, err = 20.484479904174805\n",
      "This is epoch  308\n",
      "Batch:  668/ 668 loss: 757.0941 total time:  2.36s\n",
      "Training set\n",
      "weight = 1, err = 19.892440795898438\n",
      "Testing set\n",
      "weight = 1, err = 21.00586700439453\n",
      "This is epoch  309\n",
      "Batch:  668/ 668 loss: 755.1620 total time:  2.42s\n",
      "Training set\n",
      "weight = 1, err = 19.532182693481445\n",
      "Testing set\n",
      "weight = 1, err = 20.667959213256836\n",
      "This is epoch  310\n",
      "Batch:  668/ 668 loss: 756.7855 total time:  2.34s\n",
      "Training set\n",
      "weight = 1, err = 19.414379119873047\n",
      "Testing set\n",
      "weight = 1, err = 20.482336044311523\n",
      "This is epoch  311\n",
      "Batch:  668/ 668 loss: 751.8365 total time:  2.27s\n",
      "Training set\n",
      "weight = 1, err = 19.498456954956055\n",
      "Testing set\n",
      "weight = 1, err = 20.659683227539062\n",
      "This is epoch  312\n",
      "Batch:  668/ 668 loss: 755.1216 total time:  2.26s\n",
      "Training set\n",
      "weight = 1, err = 19.511716842651367\n",
      "Testing set\n",
      "weight = 1, err = 20.5899600982666\n",
      "This is epoch  313\n",
      "Batch:  668/ 668 loss: 750.2860 total time:  2.31s\n",
      "Training set\n",
      "weight = 1, err = 20.026941299438477\n",
      "Testing set\n",
      "weight = 1, err = 20.965404510498047\n",
      "This is epoch  314\n",
      "Batch:  668/ 668 loss: 749.4077 total time:  2.07s\n",
      "Training set\n",
      "weight = 1, err = 19.43631935119629\n",
      "Testing set\n",
      "weight = 1, err = 20.504138946533203\n",
      "This is epoch  315\n",
      "Batch:  668/ 668 loss: 754.6596 total time:  2.16s\n",
      "Training set\n",
      "weight = 1, err = 19.450075149536133\n",
      "Testing set\n",
      "weight = 1, err = 20.542844772338867\n",
      "This is epoch  316\n",
      "Batch:  668/ 668 loss: 746.7673 total time:  2.20s\n",
      "Training set\n",
      "weight = 1, err = 19.429651260375977\n",
      "Testing set\n",
      "weight = 1, err = 20.54372215270996\n",
      "This is epoch  317\n",
      "Batch:  668/ 668 loss: 752.8703 total time:  2.13s\n",
      "Training set\n",
      "weight = 1, err = 19.663389205932617\n",
      "Testing set\n",
      "weight = 1, err = 20.799175262451172\n",
      "This is epoch  318\n",
      "Batch:  668/ 668 loss: 756.9733 total time:  2.19s\n",
      "Training set\n",
      "weight = 1, err = 19.455921173095703\n",
      "Testing set\n",
      "weight = 1, err = 20.587656021118164\n",
      "This is epoch  319\n",
      "Batch:  668/ 668 loss: 748.7332 total time:  2.37s\n",
      "Training set\n",
      "weight = 1, err = 19.476919174194336\n",
      "Testing set\n",
      "weight = 1, err = 20.63493537902832\n",
      "This is epoch  320\n",
      "Batch:  668/ 668 loss: 754.2671 total time:  2.37s\n",
      "Training set\n",
      "weight = 1, err = 19.643672943115234\n",
      "Testing set\n",
      "weight = 1, err = 20.79486083984375\n",
      "This is epoch  321\n",
      "Batch:  668/ 668 loss: 746.4186 total time:  2.10s\n",
      "Training set\n",
      "weight = 1, err = 19.48956871032715\n",
      "Testing set\n",
      "weight = 1, err = 20.61434555053711\n",
      "This is epoch  322\n",
      "Batch:  668/ 668 loss: 747.3201 total time:  2.26s\n",
      "Training set\n",
      "weight = 1, err = 19.394105911254883\n",
      "Testing set\n",
      "weight = 1, err = 20.49005699157715\n",
      "This is epoch  323\n",
      "Batch:  668/ 668 loss: 749.5988 total time:  2.19s\n",
      "Training set\n",
      "weight = 1, err = 19.280065536499023\n",
      "Testing set\n",
      "weight = 1, err = 20.450698852539062\n",
      "This is epoch  324\n",
      "Batch:  668/ 668 loss: 742.9430 total time:  2.38s\n",
      "Training set\n",
      "weight = 1, err = 19.576274871826172\n",
      "Testing set\n",
      "weight = 1, err = 20.63802146911621\n",
      "This is epoch  325\n",
      "Batch:  668/ 668 loss: 747.6589 total time:  2.26s\n",
      "Training set\n",
      "weight = 1, err = 19.50228500366211\n",
      "Testing set\n",
      "weight = 1, err = 20.536922454833984\n",
      "This is epoch  326\n",
      "Batch:  668/ 668 loss: 751.3223 total time:  2.17s\n",
      "Training set\n",
      "weight = 1, err = 19.51886558532715\n",
      "Testing set\n",
      "weight = 1, err = 20.596214294433594\n",
      "This is epoch  327\n",
      "Batch:  668/ 668 loss: 740.0175 total time:  2.25s\n",
      "Training set\n",
      "weight = 1, err = 19.283737182617188\n",
      "Testing set\n",
      "weight = 1, err = 20.32189178466797\n",
      "This is epoch  328\n",
      "Batch:  668/ 668 loss: 745.1835 total time:  2.14s\n",
      "Training set\n",
      "weight = 1, err = 19.534809112548828\n",
      "Testing set\n",
      "weight = 1, err = 20.64466667175293\n",
      "This is epoch  329\n",
      "Batch:  668/ 668 loss: 744.2400 total time:  2.33s\n",
      "Training set\n",
      "weight = 1, err = 19.517526626586914\n",
      "Testing set\n",
      "weight = 1, err = 20.515886306762695\n",
      "This is epoch  330\n",
      "Batch:  668/ 668 loss: 745.6862 total time:  2.34s\n",
      "Training set\n",
      "weight = 1, err = 19.208768844604492\n",
      "Testing set\n",
      "weight = 1, err = 20.318801879882812\n",
      "This is epoch  331\n",
      "Batch:  668/ 668 loss: 740.7265 total time:  2.45s\n",
      "Training set\n",
      "weight = 1, err = 19.450960159301758\n",
      "Testing set\n",
      "weight = 1, err = 20.57436180114746\n",
      "This is epoch  332\n",
      "Batch:  668/ 668 loss: 742.7532 total time:  2.47s\n",
      "Training set\n",
      "weight = 1, err = 19.63821792602539\n",
      "Testing set\n",
      "weight = 1, err = 20.651649475097656\n",
      "This is epoch  333\n",
      "Batch:  668/ 668 loss: 742.4047 total time:  2.30s\n",
      "Training set\n",
      "weight = 1, err = 19.31540870666504\n",
      "Testing set\n",
      "weight = 1, err = 20.489103317260742\n",
      "This is epoch  334\n",
      "Batch:  668/ 668 loss: 750.7693 total time:  2.17s\n",
      "Training set\n",
      "weight = 1, err = 19.850584030151367\n",
      "Testing set\n",
      "weight = 1, err = 21.019845962524414\n",
      "This is epoch  335\n",
      "Batch:  668/ 668 loss: 742.6198 total time:  2.26s\n",
      "Training set\n",
      "weight = 1, err = 19.230607986450195\n",
      "Testing set\n",
      "weight = 1, err = 20.292774200439453\n",
      "This is epoch  336\n",
      "Batch:  668/ 668 loss: 742.4259 total time:  2.10s\n",
      "Training set\n",
      "weight = 1, err = 19.35463523864746\n",
      "Testing set\n",
      "weight = 1, err = 20.481645584106445\n",
      "This is epoch  337\n",
      "Batch:  668/ 668 loss: 740.7917 total time:  1.69s\n",
      "Training set\n",
      "weight = 1, err = 19.419601440429688\n",
      "Testing set\n",
      "weight = 1, err = 20.41087532043457\n",
      "This is epoch  338\n",
      "Batch:  668/ 668 loss: 744.1015 total time:  2.00s\n",
      "Training set\n",
      "weight = 1, err = 19.673580169677734\n",
      "Testing set\n",
      "weight = 1, err = 20.70503807067871\n",
      "This is epoch  339\n",
      "Batch:  668/ 668 loss: 739.0767 total time:  2.05s\n",
      "Training set\n",
      "weight = 1, err = 19.202741622924805\n",
      "Testing set\n",
      "weight = 1, err = 20.24052619934082\n",
      "This is epoch  340\n",
      "Batch:  668/ 668 loss: 739.6542 total time:  2.16s\n",
      "Training set\n",
      "weight = 1, err = 19.64447021484375\n",
      "Testing set\n",
      "weight = 1, err = 20.858449935913086\n",
      "This is epoch  341\n",
      "Batch:  668/ 668 loss: 737.8979 total time:  2.14s\n",
      "Training set\n",
      "weight = 1, err = 19.13628387451172\n",
      "Testing set\n",
      "weight = 1, err = 20.287498474121094\n",
      "This is epoch  342\n",
      "Batch:  668/ 668 loss: 743.7441 total time:  2.17s\n",
      "Training set\n",
      "weight = 1, err = 19.483253479003906\n",
      "Testing set\n",
      "weight = 1, err = 20.66677474975586\n",
      "This is epoch  343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  668/ 668 loss: 735.6705 total time:  2.27s\n",
      "Training set\n",
      "weight = 1, err = 19.176647186279297\n",
      "Testing set\n",
      "weight = 1, err = 20.261878967285156\n",
      "This is epoch  344\n",
      "Batch:  668/ 668 loss: 741.2969 total time:  2.19s\n",
      "Training set\n",
      "weight = 1, err = 19.405502319335938\n",
      "Testing set\n",
      "weight = 1, err = 20.59138298034668\n",
      "This is epoch  345\n",
      "Batch:  668/ 668 loss: 738.2103 total time:  2.24s\n",
      "Training set\n",
      "weight = 1, err = 19.676183700561523\n",
      "Testing set\n",
      "weight = 1, err = 20.6610107421875\n",
      "This is epoch  346\n",
      "Batch:  668/ 668 loss: 741.1658 total time:  2.27s\n",
      "Training set\n",
      "weight = 1, err = 19.34170150756836\n",
      "Testing set\n",
      "weight = 1, err = 20.512779235839844\n",
      "This is epoch  347\n",
      "Batch:  668/ 668 loss: 746.8428 total time:  2.28s\n",
      "Training set\n",
      "weight = 1, err = 19.576759338378906\n",
      "Testing set\n",
      "weight = 1, err = 20.59889793395996\n",
      "This is epoch  348\n",
      "Batch:  668/ 668 loss: 735.2802 total time:  1.68s\n",
      "Training set\n",
      "weight = 1, err = 20.19063377380371\n",
      "Testing set\n",
      "weight = 1, err = 21.381540298461914\n",
      "This is epoch  349\n",
      "Batch:  668/ 668 loss: 735.1049 total time:  2.17s\n",
      "Training set\n",
      "weight = 1, err = 19.29308319091797\n",
      "Testing set\n",
      "weight = 1, err = 20.412534713745117\n",
      "This is epoch  350\n",
      "Batch:  668/ 668 loss: 741.5628 total time:  2.23s\n",
      "Training set\n",
      "weight = 1, err = 19.556081771850586\n",
      "Testing set\n",
      "weight = 1, err = 20.67080307006836\n",
      "This is epoch  351\n",
      "Batch:  668/ 668 loss: 735.8648 total time:  2.26s\n",
      "Training set\n",
      "weight = 1, err = 19.27910614013672\n",
      "Testing set\n",
      "weight = 1, err = 20.41042709350586\n",
      "This is epoch  352\n",
      "Batch:  668/ 668 loss: 735.8794 total time:  2.18s\n",
      "Training set\n",
      "weight = 1, err = 19.217622756958008\n",
      "Testing set\n",
      "weight = 1, err = 20.26812171936035\n",
      "This is epoch  353\n",
      "Batch:  668/ 668 loss: 731.1124 total time:  2.16s\n",
      "Training set\n",
      "weight = 1, err = 20.482255935668945\n",
      "Testing set\n",
      "weight = 1, err = 21.493488311767578\n",
      "This is epoch  354\n",
      "Batch:  668/ 668 loss: 735.3116 total time:  2.15s\n",
      "Training set\n",
      "weight = 1, err = 19.452451705932617\n",
      "Testing set\n",
      "weight = 1, err = 20.625974655151367\n",
      "This is epoch  355\n",
      "Batch:  668/ 668 loss: 745.7252 total time:  2.09s\n",
      "Training set\n",
      "weight = 1, err = 19.108821868896484\n",
      "Testing set\n",
      "weight = 1, err = 20.22585678100586\n",
      "This is epoch  356\n",
      "Batch:  668/ 668 loss: 729.3780 total time:  2.17s\n",
      "Training set\n",
      "weight = 1, err = 19.031339645385742\n",
      "Testing set\n",
      "weight = 1, err = 20.200620651245117\n",
      "This is epoch  357\n",
      "Batch:  668/ 668 loss: 728.2871 total time:  2.11s\n",
      "Training set\n",
      "weight = 1, err = 19.410837173461914\n",
      "Testing set\n",
      "weight = 1, err = 20.4625186920166\n",
      "This is epoch  358\n",
      "Batch:  668/ 668 loss: 732.7191 total time:  2.15s\n",
      "Training set\n",
      "weight = 1, err = 19.20403480529785\n",
      "Testing set\n",
      "weight = 1, err = 20.35335922241211\n",
      "This is epoch  359\n",
      "Batch:  668/ 668 loss: 729.6648 total time:  2.07s\n",
      "Training set\n",
      "weight = 1, err = 19.439321517944336\n",
      "Testing set\n",
      "weight = 1, err = 20.65369987487793\n",
      "This is epoch  360\n",
      "Batch:  668/ 668 loss: 734.6028 total time:  2.25s\n",
      "Training set\n",
      "weight = 1, err = 19.13677406311035\n",
      "Testing set\n",
      "weight = 1, err = 20.399028778076172\n",
      "This is epoch  361\n",
      "Batch:  668/ 668 loss: 736.6825 total time:  2.19s\n",
      "Training set\n",
      "weight = 1, err = 19.16460609436035\n",
      "Testing set\n",
      "weight = 1, err = 20.30337905883789\n",
      "This is epoch  362\n",
      "Batch:  668/ 668 loss: 727.1917 total time:  2.18s\n",
      "Training set\n",
      "weight = 1, err = 19.47079086303711\n",
      "Testing set\n",
      "weight = 1, err = 20.611391067504883\n",
      "This is epoch  363\n",
      "Batch:  668/ 668 loss: 732.9456 total time:  2.16s\n",
      "Training set\n",
      "weight = 1, err = 19.445209503173828\n",
      "Testing set\n",
      "weight = 1, err = 20.67703628540039\n",
      "This is epoch  364\n",
      "Batch:  668/ 668 loss: 731.0023 total time:  2.23s\n",
      "Training set\n",
      "weight = 1, err = 19.296606063842773\n",
      "Testing set\n",
      "weight = 1, err = 20.389873504638672\n",
      "This is epoch  365\n",
      "Batch:  668/ 668 loss: 730.2041 total time:  2.25s\n",
      "Training set\n",
      "weight = 1, err = 18.98599624633789\n",
      "Testing set\n",
      "weight = 1, err = 20.121068954467773\n",
      "This is epoch  366\n",
      "Batch:  668/ 668 loss: 733.1408 total time:  2.16s\n",
      "Training set\n",
      "weight = 1, err = 19.2002010345459\n",
      "Testing set\n",
      "weight = 1, err = 20.283275604248047\n",
      "This is epoch  367\n",
      "Batch:  668/ 668 loss: 732.2365 total time:  2.24s\n",
      "Training set\n",
      "weight = 1, err = 20.434324264526367\n",
      "Testing set\n",
      "weight = 1, err = 21.44048309326172\n",
      "This is epoch  368\n",
      "Batch:  668/ 668 loss: 729.9808 total time:  2.22s\n",
      "Training set\n",
      "weight = 1, err = 19.264747619628906\n",
      "Testing set\n",
      "weight = 1, err = 20.45014190673828\n",
      "This is epoch  369\n",
      "Batch:  668/ 668 loss: 731.9817 total time:  2.14s\n",
      "Training set\n",
      "weight = 1, err = 19.145105361938477\n",
      "Testing set\n",
      "weight = 1, err = 20.241796493530273\n",
      "This is epoch  370\n",
      "Batch:  668/ 668 loss: 728.5282 total time:  2.14s\n",
      "Training set\n",
      "weight = 1, err = 20.014009475708008\n",
      "Testing set\n",
      "weight = 1, err = 21.074296951293945\n",
      "This is epoch  371\n",
      "Batch:  668/ 668 loss: 729.7682 total time:  2.26s\n",
      "Training set\n",
      "weight = 1, err = 19.05246353149414\n",
      "Testing set\n",
      "weight = 1, err = 20.243824005126953\n",
      "This is epoch  372\n",
      "Batch:  668/ 668 loss: 725.9950 total time:  2.16s\n",
      "Training set\n",
      "weight = 1, err = 19.472009658813477\n",
      "Testing set\n",
      "weight = 1, err = 20.638702392578125\n",
      "This is epoch  373\n",
      "Batch:  668/ 668 loss: 729.2822 total time:  2.16s\n",
      "Training set\n",
      "weight = 1, err = 19.449607849121094\n",
      "Testing set\n",
      "weight = 1, err = 20.58118438720703\n",
      "This is epoch  374\n",
      "Batch:  668/ 668 loss: 726.5720 total time:  2.22s\n",
      "Training set\n",
      "weight = 1, err = 19.403947830200195\n",
      "Testing set\n",
      "weight = 1, err = 20.633289337158203\n",
      "This is epoch  375\n",
      "Batch:  668/ 668 loss: 730.3559 total time:  2.11s\n",
      "Training set\n",
      "weight = 1, err = 18.93022918701172\n",
      "Testing set\n",
      "weight = 1, err = 20.099994659423828\n",
      "This is epoch  376\n",
      "Batch:  668/ 668 loss: 728.5857 total time:  2.13s\n",
      "Training set\n",
      "weight = 1, err = 19.00170135498047\n",
      "Testing set\n",
      "weight = 1, err = 20.14826202392578\n",
      "This is epoch  377\n",
      "Batch:  668/ 668 loss: 728.5767 total time:  2.17s\n",
      "Training set\n",
      "weight = 1, err = 19.305591583251953\n",
      "Testing set\n",
      "weight = 1, err = 20.376680374145508\n",
      "This is epoch  378\n",
      "Batch:  668/ 668 loss: 727.2256 total time:  2.21s\n",
      "Training set\n",
      "weight = 1, err = 18.965253829956055\n",
      "Testing set\n",
      "weight = 1, err = 20.131486892700195\n",
      "This is epoch  379\n",
      "Batch:  668/ 668 loss: 734.7158 total time:  2.45s\n",
      "Training set\n",
      "weight = 1, err = 20.438716888427734\n",
      "Testing set\n",
      "weight = 1, err = 21.466312408447266\n",
      "This is epoch  380\n",
      "Batch:  668/ 668 loss: 725.5489 total time:  2.42s\n",
      "Training set\n",
      "weight = 1, err = 19.009681701660156\n",
      "Testing set\n",
      "weight = 1, err = 20.165071487426758\n",
      "This is epoch  381\n",
      "Batch:  668/ 668 loss: 724.8786 total time:  2.10s\n",
      "Training set\n",
      "weight = 1, err = 19.31020736694336\n",
      "Testing set\n",
      "weight = 1, err = 20.419246673583984\n",
      "This is epoch  382\n",
      "Batch:  668/ 668 loss: 733.8559 total time:  2.23s\n",
      "Training set\n",
      "weight = 1, err = 19.031631469726562\n",
      "Testing set\n",
      "weight = 1, err = 20.192829132080078\n",
      "This is epoch  383\n",
      "Batch:  668/ 668 loss: 728.0471 total time:  2.05s\n",
      "Training set\n",
      "weight = 1, err = 19.120864868164062\n",
      "Testing set\n",
      "weight = 1, err = 20.356250762939453\n",
      "This is epoch  384\n",
      "Batch:  668/ 668 loss: 723.5314 total time:  1.93s\n",
      "Training set\n",
      "weight = 1, err = 18.96742820739746\n",
      "Testing set\n",
      "weight = 1, err = 20.120634078979492\n",
      "This is epoch  385\n",
      "Batch:  668/ 668 loss: 721.8411 total time:  2.20s\n",
      "Training set\n",
      "weight = 1, err = 18.91403579711914\n",
      "Testing set\n",
      "weight = 1, err = 20.133203506469727\n",
      "This is epoch  386\n",
      "Batch:  668/ 668 loss: 725.6781 total time:  2.09s\n",
      "Training set\n",
      "weight = 1, err = 19.14260482788086\n",
      "Testing set\n",
      "weight = 1, err = 20.294933319091797\n",
      "This is epoch  387\n",
      "Batch:  668/ 668 loss: 726.8973 total time:  2.23s\n",
      "Training set\n",
      "weight = 1, err = 19.26464080810547\n",
      "Testing set\n",
      "weight = 1, err = 20.469606399536133\n",
      "This is epoch  388\n",
      "Batch:  668/ 668 loss: 726.6216 total time:  2.41s\n",
      "Training set\n",
      "weight = 1, err = 19.083948135375977\n",
      "Testing set\n",
      "weight = 1, err = 20.23907470703125\n",
      "This is epoch  389\n",
      "Batch:  668/ 668 loss: 721.7656 total time:  2.22s\n",
      "Training set\n",
      "weight = 1, err = 19.210098266601562\n",
      "Testing set\n",
      "weight = 1, err = 20.490201950073242\n",
      "This is epoch  390\n",
      "Batch:  668/ 668 loss: 723.9286 total time:  2.26s\n",
      "Training set\n",
      "weight = 1, err = 19.13903045654297\n",
      "Testing set\n",
      "weight = 1, err = 20.384239196777344\n",
      "This is epoch  391\n",
      "Batch:  668/ 668 loss: 727.5729 total time:  1.99s\n",
      "Training set\n",
      "weight = 1, err = 19.027233123779297\n",
      "Testing set\n",
      "weight = 1, err = 20.169780731201172\n",
      "This is epoch  392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  668/ 668 loss: 724.2034 total time:  2.17s\n",
      "Training set\n",
      "weight = 1, err = 18.95958137512207\n",
      "Testing set\n",
      "weight = 1, err = 20.20081901550293\n",
      "This is epoch  393\n",
      "Batch:  668/ 668 loss: 729.4570 total time:  2.03s\n",
      "Training set\n",
      "weight = 1, err = 19.27851676940918\n",
      "Testing set\n",
      "weight = 1, err = 20.27580451965332\n",
      "This is epoch  394\n",
      "Batch:  668/ 668 loss: 720.5376 total time:  2.25s\n",
      "Training set\n",
      "weight = 1, err = 19.110990524291992\n",
      "Testing set\n",
      "weight = 1, err = 20.307758331298828\n",
      "This is epoch  395\n",
      "Batch:  668/ 668 loss: 721.1852 total time:  2.16s\n",
      "Training set\n",
      "weight = 1, err = 19.139877319335938\n",
      "Testing set\n",
      "weight = 1, err = 20.20796775817871\n",
      "This is epoch  396\n",
      "Batch:  668/ 668 loss: 720.6565 total time:  2.20s\n",
      "Training set\n",
      "weight = 1, err = 19.3281307220459\n",
      "Testing set\n",
      "weight = 1, err = 20.39727783203125\n",
      "This is epoch  397\n",
      "Batch:  668/ 668 loss: 728.1810 total time:  2.17s\n",
      "Training set\n",
      "weight = 1, err = 18.872291564941406\n",
      "Testing set\n",
      "weight = 1, err = 20.092716217041016\n",
      "This is epoch  398\n",
      "Batch:  668/ 668 loss: 721.8804 total time:  2.11s\n",
      "Training set\n",
      "weight = 1, err = 18.979839324951172\n",
      "Testing set\n",
      "weight = 1, err = 20.150224685668945\n",
      "This is epoch  399\n",
      "Batch:  668/ 668 loss: 735.8174 total time:  2.20s\n",
      "Training set\n",
      "weight = 1, err = 19.196949005126953\n",
      "Testing set\n",
      "weight = 1, err = 20.301633834838867\n",
      "This is epoch  400\n",
      "Batch:  668/ 668 loss: 729.0909 total time:  2.13s\n",
      "Training set\n",
      "weight = 1, err = 19.02623176574707\n",
      "Testing set\n",
      "weight = 1, err = 20.17203712463379\n",
      "This is epoch  401\n",
      "Batch:  668/ 668 loss: 720.3890 total time:  2.18s\n",
      "Training set\n",
      "weight = 1, err = 18.987255096435547\n",
      "Testing set\n",
      "weight = 1, err = 20.137367248535156\n",
      "This is epoch  402\n",
      "Batch:  668/ 668 loss: 726.5989 total time:  2.11s\n",
      "Training set\n",
      "weight = 1, err = 18.945632934570312\n",
      "Testing set\n",
      "weight = 1, err = 20.140642166137695\n",
      "This is epoch  403\n",
      "Batch:  668/ 668 loss: 715.5907 total time:  2.15s\n",
      "Training set\n",
      "weight = 1, err = 19.302854537963867\n",
      "Testing set\n",
      "weight = 1, err = 20.348230361938477\n",
      "This is epoch  404\n",
      "Batch:  668/ 668 loss: 728.6336 total time:  2.22s\n",
      "Training set\n",
      "weight = 1, err = 18.81963539123535\n",
      "Testing set\n",
      "weight = 1, err = 19.961374282836914\n",
      "This is epoch  405\n",
      "Batch:  668/ 668 loss: 722.1918 total time:  2.22s\n",
      "Training set\n",
      "weight = 1, err = 19.661203384399414\n",
      "Testing set\n",
      "weight = 1, err = 20.811853408813477\n",
      "This is epoch  406\n",
      "Batch:  668/ 668 loss: 717.9433 total time:  2.24s\n",
      "Training set\n",
      "weight = 1, err = 18.91729164123535\n",
      "Testing set\n",
      "weight = 1, err = 20.1975040435791\n",
      "This is epoch  407\n",
      "Batch:  668/ 668 loss: 720.7911 total time:  2.30s\n",
      "Training set\n",
      "weight = 1, err = 19.042818069458008\n",
      "Testing set\n",
      "weight = 1, err = 20.234935760498047\n",
      "This is epoch  408\n",
      "Batch:  668/ 668 loss: 718.8244 total time:  2.23s\n",
      "Training set\n",
      "weight = 1, err = 19.108022689819336\n",
      "Testing set\n",
      "weight = 1, err = 20.427003860473633\n",
      "This is epoch  409\n",
      "Batch:  668/ 668 loss: 721.3637 total time:  2.12s\n",
      "Training set\n",
      "weight = 1, err = 19.047075271606445\n",
      "Testing set\n",
      "weight = 1, err = 20.157604217529297\n",
      "This is epoch  410\n",
      "Batch:  668/ 668 loss: 715.3036 total time:  2.25s\n",
      "Training set\n",
      "weight = 1, err = 19.862674713134766\n",
      "Testing set\n",
      "weight = 1, err = 21.130342483520508\n",
      "This is epoch  411\n",
      "Batch:  668/ 668 loss: 721.6867 total time:  2.26s\n",
      "Training set\n",
      "weight = 1, err = 19.536550521850586\n",
      "Testing set\n",
      "weight = 1, err = 20.72090721130371\n",
      "This is epoch  412\n",
      "Batch:  668/ 668 loss: 720.1269 total time:  2.27s\n",
      "Training set\n",
      "weight = 1, err = 18.864660263061523\n",
      "Testing set\n",
      "weight = 1, err = 20.08713722229004\n",
      "This is epoch  413\n",
      "Batch:  668/ 668 loss: 720.7482 total time:  2.12s\n",
      "Training set\n",
      "weight = 1, err = 18.949176788330078\n",
      "Testing set\n",
      "weight = 1, err = 20.138568878173828\n",
      "This is epoch  414\n",
      "Batch:  668/ 668 loss: 712.8903 total time:  2.16s\n",
      "Training set\n",
      "weight = 1, err = 18.885581970214844\n",
      "Testing set\n",
      "weight = 1, err = 20.162212371826172\n",
      "This is epoch  415\n",
      "Batch:  668/ 668 loss: 713.6603 total time:  2.33s\n",
      "Training set\n",
      "weight = 1, err = 19.119216918945312\n",
      "Testing set\n",
      "weight = 1, err = 20.388368606567383\n",
      "This is epoch  416\n",
      "Batch:  668/ 668 loss: 720.9337 total time:  2.41s\n",
      "Training set\n",
      "weight = 1, err = 18.87495231628418\n",
      "Testing set\n",
      "weight = 1, err = 20.130477905273438\n",
      "This is epoch  417\n",
      "Batch:  668/ 668 loss: 718.7005 total time:  2.09s\n",
      "Training set\n",
      "weight = 1, err = 19.10928726196289\n",
      "Testing set\n",
      "weight = 1, err = 20.24762725830078\n",
      "This is epoch  418\n",
      "Batch:  668/ 668 loss: 715.4167 total time:  2.27s\n",
      "Training set\n",
      "weight = 1, err = 19.007526397705078\n",
      "Testing set\n",
      "weight = 1, err = 20.113239288330078\n",
      "This is epoch  419\n",
      "Batch:  668/ 668 loss: 716.2381 total time:  2.25s\n",
      "Training set\n",
      "weight = 1, err = 18.896343231201172\n",
      "Testing set\n",
      "weight = 1, err = 20.117948532104492\n",
      "This is epoch  420\n",
      "Batch:  668/ 668 loss: 721.1683 total time:  2.18s\n",
      "Training set\n",
      "weight = 1, err = 19.8627986907959\n",
      "Testing set\n",
      "weight = 1, err = 20.942916870117188\n",
      "This is epoch  421\n",
      "Batch:  668/ 668 loss: 721.2910 total time:  1.90s\n",
      "Training set\n",
      "weight = 1, err = 18.762731552124023\n",
      "Testing set\n",
      "weight = 1, err = 19.9735050201416\n",
      "This is epoch  422\n",
      "Batch:  668/ 668 loss: 710.9563 total time:  1.92s\n",
      "Training set\n",
      "weight = 1, err = 19.040475845336914\n",
      "Testing set\n",
      "weight = 1, err = 20.24420738220215\n",
      "This is epoch  423\n",
      "Batch:  668/ 668 loss: 725.1435 total time:  2.12s\n",
      "Training set\n",
      "weight = 1, err = 18.95572853088379\n",
      "Testing set\n",
      "weight = 1, err = 20.173959732055664\n",
      "This is epoch  424\n",
      "Batch:  668/ 668 loss: 714.6580 total time:  2.02s\n",
      "Training set\n",
      "weight = 1, err = 19.03705596923828\n",
      "Testing set\n",
      "weight = 1, err = 20.3343448638916\n",
      "This is epoch  425\n",
      "Batch:  668/ 668 loss: 714.2152 total time:  2.25s\n",
      "Training set\n",
      "weight = 1, err = 18.993000030517578\n",
      "Testing set\n",
      "weight = 1, err = 20.250850677490234\n",
      "This is epoch  426\n",
      "Batch:  668/ 668 loss: 712.8935 total time:  2.18s\n",
      "Training set\n",
      "weight = 1, err = 18.978967666625977\n",
      "Testing set\n",
      "weight = 1, err = 20.236602783203125\n",
      "This is epoch  427\n",
      "Batch:  668/ 668 loss: 714.6043 total time:  2.13s\n",
      "Training set\n",
      "weight = 1, err = 19.078277587890625\n",
      "Testing set\n",
      "weight = 1, err = 20.345470428466797\n",
      "This is epoch  428\n",
      "Batch:  668/ 668 loss: 716.5430 total time:  2.25s\n",
      "Training set\n",
      "weight = 1, err = 18.886974334716797\n",
      "Testing set\n",
      "weight = 1, err = 20.152463912963867\n",
      "This is epoch  429\n",
      "Batch:  668/ 668 loss: 714.5837 total time:  1.76s\n",
      "Training set\n",
      "weight = 1, err = 19.34954071044922\n",
      "Testing set\n",
      "weight = 1, err = 20.665870666503906\n",
      "This is epoch  430\n",
      "Batch:  668/ 668 loss: 715.3713 total time:  2.14s\n",
      "Training set\n",
      "weight = 1, err = 19.45728874206543\n",
      "Testing set\n",
      "weight = 1, err = 20.528400421142578\n",
      "This is epoch  431\n",
      "Batch:  668/ 668 loss: 710.5161 total time:  1.68s\n",
      "Training set\n",
      "weight = 1, err = 18.97795295715332\n",
      "Testing set\n",
      "weight = 1, err = 20.146800994873047\n",
      "This is epoch  432\n",
      "Batch:  668/ 668 loss: 719.1910 total time:  2.05s\n",
      "Training set\n",
      "weight = 1, err = 18.949832916259766\n",
      "Testing set\n",
      "weight = 1, err = 20.15847396850586\n",
      "This is epoch  433\n",
      "Batch:  668/ 668 loss: 709.5777 total time:  2.03s\n",
      "Training set\n",
      "weight = 1, err = 18.652482986450195\n",
      "Testing set\n",
      "weight = 1, err = 19.850984573364258\n",
      "This is epoch  434\n",
      "Batch:  668/ 668 loss: 712.3268 total time:  2.12s\n",
      "Training set\n",
      "weight = 1, err = 19.151914596557617\n",
      "Testing set\n",
      "weight = 1, err = 20.2918758392334\n",
      "This is epoch  435\n",
      "Batch:  668/ 668 loss: 719.6061 total time:  2.12s\n",
      "Training set\n",
      "weight = 1, err = 19.014663696289062\n",
      "Testing set\n",
      "weight = 1, err = 20.182058334350586\n",
      "This is epoch  436\n",
      "Batch:  668/ 668 loss: 711.8609 total time:  2.24s\n",
      "Training set\n",
      "weight = 1, err = 19.273460388183594\n",
      "Testing set\n",
      "weight = 1, err = 20.59298324584961\n",
      "This is epoch  437\n",
      "Batch:  668/ 668 loss: 716.6068 total time:  2.21s\n",
      "Training set\n",
      "weight = 1, err = 18.820114135742188\n",
      "Testing set\n",
      "weight = 1, err = 20.067094802856445\n",
      "This is epoch  438\n",
      "Batch:  668/ 668 loss: 709.9131 total time:  2.23s\n",
      "Training set\n",
      "weight = 1, err = 18.748159408569336\n",
      "Testing set\n",
      "weight = 1, err = 19.924896240234375\n",
      "This is epoch  439\n",
      "Batch:  668/ 668 loss: 714.4352 total time:  2.40s\n",
      "Training set\n",
      "weight = 1, err = 19.873987197875977\n",
      "Testing set\n",
      "weight = 1, err = 20.90712547302246\n",
      "This is epoch  440\n",
      "Batch:  668/ 668 loss: 711.5555 total time:  2.38s\n",
      "Training set\n",
      "weight = 1, err = 18.680389404296875\n",
      "Testing set\n",
      "weight = 1, err = 19.885101318359375\n",
      "This is epoch  441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  668/ 668 loss: 715.9403 total time:  2.34s\n",
      "Training set\n",
      "weight = 1, err = 18.777555465698242\n",
      "Testing set\n",
      "weight = 1, err = 19.982667922973633\n",
      "This is epoch  442\n",
      "Batch:  668/ 668 loss: 714.8762 total time:  2.48s\n",
      "Training set\n",
      "weight = 1, err = 18.944490432739258\n",
      "Testing set\n",
      "weight = 1, err = 20.111675262451172\n",
      "This is epoch  443\n",
      "Batch:  668/ 668 loss: 714.6441 total time:  2.23s\n",
      "Training set\n",
      "weight = 1, err = 18.946094512939453\n",
      "Testing set\n",
      "weight = 1, err = 20.239168167114258\n",
      "This is epoch  444\n",
      "Batch:  668/ 668 loss: 708.7897 total time:  2.45s\n",
      "Training set\n",
      "weight = 1, err = 19.058238983154297\n",
      "Testing set\n",
      "weight = 1, err = 20.329051971435547\n",
      "This is epoch  445\n",
      "Batch:  668/ 668 loss: 710.4891 total time:  2.29s\n",
      "Training set\n",
      "weight = 1, err = 18.92129898071289\n",
      "Testing set\n",
      "weight = 1, err = 20.150543212890625\n",
      "This is epoch  446\n",
      "Batch:  668/ 668 loss: 709.0718 total time:  2.21s\n",
      "Training set\n",
      "weight = 1, err = 18.894508361816406\n",
      "Testing set\n",
      "weight = 1, err = 20.187564849853516\n",
      "This is epoch  447\n",
      "Batch:  668/ 668 loss: 712.2288 total time:  2.16s\n",
      "Training set\n",
      "weight = 1, err = 18.813966751098633\n",
      "Testing set\n",
      "weight = 1, err = 20.177263259887695\n",
      "This is epoch  448\n",
      "Batch:  668/ 668 loss: 708.5215 total time:  2.10s\n",
      "Training set\n",
      "weight = 1, err = 18.762451171875\n",
      "Testing set\n",
      "weight = 1, err = 20.044790267944336\n",
      "This is epoch  449\n",
      "Batch:  668/ 668 loss: 713.2224 total time:  2.26s\n",
      "Training set\n",
      "weight = 1, err = 19.184240341186523\n",
      "Testing set\n",
      "weight = 1, err = 20.476037979125977\n",
      "This is epoch  450\n",
      "Batch:  668/ 668 loss: 708.3455 total time:  2.44s\n",
      "Training set\n",
      "weight = 1, err = 19.067581176757812\n",
      "Testing set\n",
      "weight = 1, err = 20.33832550048828\n",
      "This is epoch  451\n",
      "Batch:  668/ 668 loss: 708.9941 total time:  2.17s\n",
      "Training set\n",
      "weight = 1, err = 18.74951934814453\n",
      "Testing set\n",
      "weight = 1, err = 19.986791610717773\n",
      "This is epoch  452\n",
      "Batch:  668/ 668 loss: 712.3317 total time:  2.28s\n",
      "Training set\n",
      "weight = 1, err = 18.62195587158203\n",
      "Testing set\n",
      "weight = 1, err = 19.872522354125977\n",
      "This is epoch  453\n",
      "Batch:  668/ 668 loss: 708.7684 total time:  2.38s\n",
      "Training set\n",
      "weight = 1, err = 18.897035598754883\n",
      "Testing set\n",
      "weight = 1, err = 20.23180389404297\n",
      "This is epoch  454\n",
      "Batch:  668/ 668 loss: 702.1864 total time:  2.33s\n",
      "Training set\n",
      "weight = 1, err = 19.10855484008789\n",
      "Testing set\n",
      "weight = 1, err = 20.510160446166992\n",
      "This is epoch  455\n",
      "Batch:  668/ 668 loss: 707.8364 total time:  2.19s\n",
      "Training set\n",
      "weight = 1, err = 18.786022186279297\n",
      "Testing set\n",
      "weight = 1, err = 19.98319435119629\n",
      "This is epoch  456\n",
      "Batch:  668/ 668 loss: 709.4644 total time:  2.29s\n",
      "Training set\n",
      "weight = 1, err = 19.014562606811523\n",
      "Testing set\n",
      "weight = 1, err = 20.332075119018555\n",
      "This is epoch  457\n",
      "Batch:  668/ 668 loss: 710.8006 total time:  2.25s\n",
      "Training set\n",
      "weight = 1, err = 19.38442039489746\n",
      "Testing set\n",
      "weight = 1, err = 20.48253059387207\n",
      "This is epoch  458\n",
      "Batch:  668/ 668 loss: 709.0305 total time:  2.27s\n",
      "Training set\n",
      "weight = 1, err = 18.90683364868164\n",
      "Testing set\n",
      "weight = 1, err = 20.064212799072266\n",
      "This is epoch  459\n",
      "Batch:  668/ 668 loss: 709.1060 total time:  2.23s\n",
      "Training set\n",
      "weight = 1, err = 19.530948638916016\n",
      "Testing set\n",
      "weight = 1, err = 20.72205352783203\n",
      "This is epoch  460\n",
      "Batch:  668/ 668 loss: 707.3918 total time:  2.26s\n",
      "Training set\n",
      "weight = 1, err = 19.02137565612793\n",
      "Testing set\n",
      "weight = 1, err = 20.284387588500977\n",
      "This is epoch  461\n",
      "Batch:  668/ 668 loss: 708.1789 total time:  2.20s\n",
      "Training set\n",
      "weight = 1, err = 19.036205291748047\n",
      "Testing set\n",
      "weight = 1, err = 20.302064895629883\n",
      "This is epoch  462\n",
      "Batch:  668/ 668 loss: 706.7159 total time:  2.46s\n",
      "Training set\n",
      "weight = 1, err = 18.85228729248047\n",
      "Testing set\n",
      "weight = 1, err = 20.044004440307617\n",
      "This is epoch  463\n",
      "Batch:  668/ 668 loss: 704.4275 total time:  2.24s\n",
      "Training set\n",
      "weight = 1, err = 19.253541946411133\n",
      "Testing set\n",
      "weight = 1, err = 20.36294174194336\n",
      "This is epoch  464\n",
      "Batch:  668/ 668 loss: 712.6522 total time:  2.28s\n",
      "Training set\n",
      "weight = 1, err = 19.099157333374023\n",
      "Testing set\n",
      "weight = 1, err = 20.478822708129883\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "model = linear_model().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "w = torch.as_tensor([300,1, 200],dtype=torch.float,device=device).unsqueeze(0)\n",
    "best_tr, best_val = np.inf, np.inf\n",
    "for epoch in range(1000):\n",
    "    print('This is epoch {:4d}'.format(epoch))\n",
    "    total_loss = 0\n",
    "    st = time.time()\n",
    "    for i,(x,y) in enumerate(tr, 1):\n",
    "        x = x.to(device)\n",
    "        y = (y[:,1]).squeeze().to(device)\n",
    "        model.zero_grad()\n",
    "\n",
    "        y_pred = model(x).squeeze()\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "            \n",
    "        print(\"Batch: {:4d}/{:4d} loss: {:.4f}\".format(i, len(tr), total_loss/i),\n",
    "                  end=' '*5+'\\r' if i != len(tr) else ' ')\n",
    "    print('total time: {:>5.2f}s'.format(time.time()-st))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        x = normalized_X.to(device)\n",
    "        pre_y = model(x.squeeze()).detach().cpu().squeeze()\n",
    "        print(\"Training set\")\n",
    "        WERR(1,pre_y,Y[:,1])\n",
    "        vx = normalized_VX.to(device)\n",
    "        pre_vy = model(vx.squeeze()).detach().cpu().squeeze()\n",
    "        print(\"Testing set\")\n",
    "        l = float(WERR(1,pre_vy,VY[:,1]))\n",
    "        if l < best_val:\n",
    "            best_val = l\n",
    "            torch.save(model.state_dict(), 'mesh_model.pt')\n",
    "            iter_nochange = 0\n",
    "        else:\n",
    "            iter_nochange += 1\n",
    "        if iter_nochange > 30:\n",
    "            break\n",
    "\n",
    "print(iter_nochange)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=linear_model()\n",
    "model.load_state_dict(torch.load('alpha_model.pt'))\n",
    "model.eval()\n",
    "alpha_tr = model(normalized_X)\n",
    "alpha_te_val = model(normalized_VX)\n",
    "alpha_te = model(normalized_TX)\n",
    "model.load_state_dict(torch.load('mesh_model.pt'))\n",
    "model.eval()\n",
    "mesh_tr = model(normalized_X)\n",
    "mesh_te_val = model(normalized_VX)\n",
    "mesh_te = model(normalized_TX)\n",
    "model.load_state_dict(torch.load('rate_model.pt'))\n",
    "model.eval()\n",
    "rate_tr = model(normalized_X)\n",
    "rate_te_val = model(normalized_VX)\n",
    "rate_te = model(normalized_TX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Y_pre_tr = np.array([rate_tr,meshsize_tr,alpha_tr]).T\n",
    "Y_pre_te_val = np.array([rate_te_val,meshsize_te_val,alpha_te_val]).T\n",
    "Y_pre_te = np.array([rate_te,meshsize_te,alpha_te]).T\n",
    "\n",
    "#np.savetxt('MLP_v7.csv', Y_pre_te, delimiter=',')\n",
    "err(Y_pre_tr,Y)\n",
    "err(Y_pre_te_val,VY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rnn_feature(Dataset):\n",
    "    def __init__(self, X, Y, TX, TY, train=True):\n",
    "        self.train = train        \n",
    "        self.x = X\n",
    "        self.y = Y\n",
    "        self.tx = TX\n",
    "        self.ty = TY\n",
    "    def __len__(self):\n",
    "        return(len(self.x) if self.train else len(self.tx))\n",
    "    def __getitem__(self,idx):\n",
    "        tmp_y = self.y[idx] if self.train else ty[idx]\n",
    "        return(self.x[idx].view(50,100) if self.train else self.tx[idx].view(50,100), tmp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.c1 = nn.Conv1d(input_size, hidden_size, 2)\n",
    "        self.p1 = nn.AvgPool1d(2)\n",
    "        self.c2 = nn.Conv1d(hidden_size, hidden_size, 1)\n",
    "        self.p2 = nn.AvgPool1d(2)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=0.01)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        batch_size = inputs.size(1)\n",
    "        \n",
    "        # Turn (seq_len x batch_size x input_size) into (batch_size x input_size x seq_len) for CNN\n",
    "        inputs = inputs.transpose(0, 1).transpose(1, 2)\n",
    "\n",
    "        # Run through Conv1d and Pool1d layers\n",
    "        c = self.c1(inputs)\n",
    "        p = self.p1(c)\n",
    "        c = self.c2(p)\n",
    "        p = self.p2(c)\n",
    "\n",
    "        # Turn (batch_size x hidden_size x seq_len) back into (seq_len x batch_size x hidden_size) for RNN\n",
    "        p = p.transpose(1, 2).transpose(0, 1)\n",
    "        \n",
    "        p = F.tanh(p)\n",
    "        output, hidden = self.gru(p, hidden)\n",
    "        conv_seq_len = output.size(0)\n",
    "        output = output.view(conv_seq_len * batch_size, self.hidden_size) # Treating (conv_seq_len x batch_size) as batch_size for linear layer\n",
    "        output = F.tanh(self.out(output))\n",
    "        output = output.view(conv_seq_len, -1, self.output_size)\n",
    "        return output, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_tr_set = rnn_feature(X[:,5000:],Y,VX[:,5000:],VY,train=True)\n",
    "rnn_te_set = rnn_feature(X[:,5000:],Y,VX[:,5000:],VY,train=False)\n",
    "\n",
    "tr = DataLoader(tr_set, batch_size=64, shuffle=True)\n",
    "te = DataLoader(te_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 100\n",
    "hidden_size = 20\n",
    "output_size = 20\n",
    "batch_size = 64\n",
    "n_layers = 2\n",
    "seq_len = 50\n",
    "\n",
    "rnn = RNN(input_size, hidden_size, output_size, n_layers=n_layers)\n",
    "\n",
    "inputs = Variable(torch.rand(seq_len, batch_size, input_size)) # seq_len x batch_size x \n",
    "outputs, hidden = rnn(inputs, None)\n",
    "print('outputs', outputs.size()) # conv_seq_len x batch_size x output_size\n",
    "print('hidden', hidden.size()) # n_layers x batch_size x hidden_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
